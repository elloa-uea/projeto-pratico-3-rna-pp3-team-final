{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Artificiais 2020.1 -- Projeto Prático 3.4\n",
    "\n",
    "**Disciplina**: Redes Neurais Artificiais 2020.1  \n",
    "**Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
    "**Github**: http://github.com/elloa  \n",
    "        \n",
    "\n",
    "Levando em conta a base de dados **_Forest Cover Type_**, esta terceira parte do Projeto Prático 3 diz respeito à proposição e avaliação de múltiplas redes neurais artificiais do tipo feedforward multilayer perceptron para o problema da classificação multi-classe da cobertura florestal em uma área do Roosevelt National Forest.\n",
    "\n",
    "## Busca em Grade\n",
    "\n",
    "Uma maneira padrão de escolher os parâmetros de um modelo de Machine Learning é por meio de uma busca em grade via força bruta. O algoritmo da busca em grade é dado como segue:\n",
    "\n",
    "1. Escolha a métrica de desempenho que você deseja maximizar  \n",
    "2. Escolha o algoritmo de Machine Learning (exemplo: redes neurais artificiais). Em seguida, defina os parâmetros ou hiperparâmetros deste tipo de modelo sobre os quais você dseja otimizar (número de épocas, taxa de aprendizado, etc.) e construa um array de valores a serem testados para cada parâmetro ou hiperparâmetro.  \n",
    "3. Defina a grade de busca, a qual é dada como o produto cartesiano de cada parâmetro a ser testado. Por exemplo, para os arrays [50, 100, 1000] e [10, 15], tem-se que a grade é [(50,10), (50,15), (100,10), (100,15), (1000,10), (1000,15)].\n",
    "4. Para cada combinação de parâmetros a serem otimizados, utilize o conjunto de treinamento para realizar uma validação cruzada (holdout ou k-fold) e calcule a métrica de avaliação no conjunto de teste (ou conjuntos de teste)\n",
    "5. Escolha a combinação de parâmetros que maximizam a métrica de avaliação. Este é o modelo otimizado.\n",
    "\n",
    "Por que esta abordagem funciona? Porque a busca em grade efetua uma pesquisa extensiva sobre as possíveis combinações de valores para cada um dos parâmetros a serem ajustados. Para cada combinação, ela estima a performance do modelo em dados novos. Por fim, o modelo com melhor métrica de desempenho é escolhido. Tem-se então que este modelo é o que melhor pode vir a generalizar mediante dados nunca antes vistos.\n",
    "\n",
    "## Efetuando a Busca em Grade sobre Hiperparâmetros das Top-6 RNAs\n",
    "\n",
    "Considerando a etapa anterior do projeto prático, foram identificadas pelo menos 6 melhores Redes Neurais para o problema da classificação multi-classe da cobertura florestal no conjunto de dados selecionado. Algumas destas redes possuem atributos categóricos como variáveis preditoras, enquanto outras possuem apenas os atributos numéricos como preditores.\n",
    "\n",
    "A primeira etapa desta segunda parte do projeto consiste em trazer para este notebook estas seis arquiteturas, ressaltando:\n",
    "\n",
    "1. Número de neurônios ocultos por camada  \n",
    "2. Função de Ativação  \n",
    "3. Utilização ou não de atributos categóricos   \n",
    "4. Desempenho médio +- desvio padrão nos testes anteriores  \n",
    "5. Número de repetições que a equipe conseguiu realizar para verificar os resultados  \n",
    "\n",
    "Elabore uma busca em grade sobre estas arquiteturas que contemple variações nos hiperparâmetros a seguir, conforme documentação de [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "\n",
    "A. Solver  (Não usar o LBFGS, pois é mais adequado para datasets pequenos)  \n",
    "B. Batch Size  \n",
    "C. Learning Rate Init  \n",
    "D. Paciência (n_iter_no_change)  \n",
    "E. Épocas  \n",
    "\n",
    "Nesta busca em grande, contemple a utilização do objeto [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação Cruzada k-fold\n",
    "\n",
    "Na elaboração da busca em grid, vamos avaliar os modelos propostos segundo uma estratégia de validação cruzada ainda não explorada até o momento: a validação cruzada k-fold. Segundo a mesma, o conjunto de dados é particionado em k partes: a cada iteração, separa-se uma das partes para teste e o modelo é treinado com as k-1 partes remanescentes. Valores sugestivos de k na literatura são k = 3, 5 ou 10, pois o custo computacional desta validação dos modelos é alto. A métrica de desempenho é resultante da média dos desempenhos nas k iterações. A figura a seguir ilustra a ideia desta avaliação\n",
    "\n",
    "<img src = \"https://ethen8181.github.io/machine-learning/model_selection/img/kfolds.png\" width=600></img>\n",
    "\n",
    "Considerando a métrica de desempenho F1-Score, considere a validação cruzada 5-fold para aferir os resultados da busca em grande anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações\n",
    "Nesta seção, foi feita:\n",
    "* Importações de bibliotecas.\n",
    "* Importação do dataset forest cover type `covtype.csv`.\n",
    "* Carregamento das top 6 arquiteturas obtidas no notebook anterior `Projeto 3.3`.  \n",
    "* Remoção dos atributos categóricos do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reservado para a importação de bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos do dataset\n",
    "é importante citar que como os maiores scores obtidos no notebook anterior foram sem o uso dos atributos categóricos, este também nao usará tais atributos.\n",
    "\n",
    "Nesta célula foi feito o carregamento do dataset e a remoção dos atributos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do dataset covtype.csv\n",
    "\n",
    "# df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/covtype.csv', sep=',')  # caso use google colab\n",
    "df = pd.read_csv('./covtype.csv')                                                   # caso faça localmente pelo jupyter\n",
    "\n",
    "atributosCategoricos = []\n",
    "for i in range(40):                                                                 # loop para preencher um vetor com os atributos categoricos\n",
    "  if i <= 3:\n",
    "    atributosCategoricos.append(\"Wilderness_Area\"+str(i+1))\n",
    "  atributosCategoricos.append(\"Soil_Type\"+str(i+1))\n",
    "\n",
    "df = df.drop(columns=atributosCategoricos)    \n",
    "\n",
    "x_preditor = df.drop(columns=[\"Cover_Type\"]) \n",
    "y_alvo = df[\"Cover_Type\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criacao do vetor com as 6 melhores configuracoes da arquitetura propria\n",
    "top6_arquiteturas = []\n",
    "\n",
    "# preenchimento do vetor com as 3 melhores configuracoes da arquitetura propria\n",
    "top6_arquiteturas.append({                                                          \n",
    "    \"camadasOcultas\": 1,\"funcaoAtivacao\": \"logistic\", \"hiperparametro\": \"adam\",\n",
    "    \"epocas\": 200, \"neuronios\": 15, \"disposicaoNeuronios\": 15, \"acuracia\": 0.73191,\n",
    "    \"fscore\":0.54205\n",
    "})\n",
    "top6_arquiteturas.append({                                                          \n",
    "    \"camadasOcultas\": 1, \"funcaoAtivacao\": \"tanh\", \"hiperparametro\": \"sgd\",\n",
    "    \"epocas\": 200, \"neuronios\": 13, \"disposicaoNeuronios\": 13, \"acuracia\": 0.72023,\n",
    "    \"fscore\":0.47931\n",
    "})\n",
    "top6_arquiteturas.append({                                                          \n",
    "    \"camadasOcultas\": 1, \"funcaoAtivacao\": \"tanh\", \"hiperparametro\": \"sgd\",\n",
    "    \"epocas\": 200, \"neuronios\": 11, \"disposicaoNeuronios\": 11, \"acuracia\": 0.71824,\n",
    "    \"fscore\":0.47116\n",
    "})\n",
    "\n",
    "# preenchimento do vetor com as 3 melhores configuracoes da arquitetura priramide\n",
    "top6_arquiteturas.append({                                                          \n",
    "    \"camadasOcultas\": 1,\"funcaoAtivacao\": \"tanh\", \"hiperparametro\": \"adam\",\n",
    "    \"epocas\": 200, \"neuronios\": 25, \"disposicaoNeuronios\": 25,  \"acuracia\": 0.74959,\n",
    "    \"fscore\":0.60096\n",
    "})\n",
    "top6_arquiteturas.append({                                                          \n",
    "    \"camadasOcultas\": 1, \"funcaoAtivacao\": \"logistic\", \"hiperparametro\": \"adam\",\n",
    "    \"epocas\": 200, \"neuronios\": 25, \"disposicaoNeuronios\": 25, \"acuracia\": 0.74573,\n",
    "    \"fscore\":0.58238\n",
    "})\n",
    "top6_arquiteturas.append({                                                          \n",
    "    \"camadasOcultas\": 2, \"funcaoAtivacao\": \"logistic\", \"hiperparametro\": \"adam\",\n",
    "    \"epocas\": 200, \"neuronios\": 25, \"disposicaoNeuronios\": (22, 3), \"acuracia\": 0.74294,\n",
    "    \"fscore\":0.53948\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstração das arquiteturas\n",
    "Nesta seção foi feita o demonstração, em forma de tabela, das top 6 configurações que serão usadas nesse projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+--------+-----------+----------------------+----------+---------+-------------+\n",
      "| Camadas |  Função  | Hiperparametro | Épocas | Neurônios | Neurônios por camada | Acurácia | F-Score | Categóricos |\n",
      "+---------+----------+----------------+--------+-----------+----------------------+----------+---------+-------------+\n",
      "|    1    | logistic |      adam      |  200   |     15    |          15          | 0.73191  | 0.54205 |     Não     |\n",
      "|    1    |   tanh   |      sgd       |  200   |     13    |          13          | 0.72023  | 0.47931 |     Não     |\n",
      "|    1    |   tanh   |      sgd       |  200   |     11    |          11          | 0.71824  | 0.47116 |     Não     |\n",
      "|    1    |   tanh   |      adam      |  200   |     25    |          25          | 0.74959  | 0.60096 |     Não     |\n",
      "|    1    | logistic |      adam      |  200   |     25    |          25          | 0.74573  | 0.58238 |     Não     |\n",
      "|    2    | logistic |      adam      |  200   |     25    |       (22, 3)        | 0.74294  | 0.53948 |     Não     |\n",
      "+---------+----------+----------------+--------+-----------+----------------------+----------+---------+-------------+\n"
     ]
    }
   ],
   "source": [
    "# Exibicao das configuracoes top 6\n",
    "\n",
    "table = PrettyTable([\"Camadas\",\"Função\",                                          # Criacao da tabela\n",
    "                      \"Hiperparametro\", \"Épocas\", \n",
    "                      \"Neurônios\", \"Neurônios por camada\", \n",
    "                     \"Acurácia\", \"F-Score\", \"Categóricos\"])        \n",
    "\n",
    "for i in top6_arquiteturas:                                                       # loop para preencher a tabela com os dados\n",
    "  table.add_row([i[\"camadasOcultas\"], i[\"funcaoAtivacao\"], i[\"hiperparametro\"],\n",
    "                i[\"epocas\"], i[\"neuronios\"], i[\"disposicaoNeuronios\"],\n",
    "                i[\"acuracia\"], i[\"fscore\"], \"Não\"])\n",
    "\n",
    "# print da tabela com as configuracoes geradas\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca em grade usando validação cruzada 5-Fold\n",
    "\n",
    "Nesta seção foi feita:\n",
    "* Criação das listas que serão usadas na validação cruzada.\n",
    "* Uso da biblioteca `GridSearchCV` para validação cruzada.\n",
    "* Treino das arquiteturas obtidas a partir do produto carteziano das listas.\n",
    "\n",
    "> É importante ressaltar que por conta de recursos computacionais limitados, foi usado listas de tamanho 2, resultando assim em 16 configurações diferentes a partir do produto cartesiano. E também que a biblioteca `GridSearchCV` usa como padrão um k-fold de 5 por isso o mesmo não foi especificado na criação da busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criacao das configuracoes para busca em grade\n",
    "\n",
    "GridSearchList = []                                                               # criacao da lista para armazenar as 6 configuracoes\n",
    "\n",
    "scoring = {                                                                       # criacao do dicionario para o score f-score\n",
    "    'f1_score': make_scorer(f1_score, average=\"macro\")\n",
    "}\n",
    "\n",
    "SolverList = [\"sgd\", \"adam\"]                                                      # lista com os parametros de solver\n",
    "BatchSizeList = [350000]                                                          # lista com o parametros de batch size\n",
    "LearningRateList = [0.01, 0.02]                                                   # lista com os valores de taxa incial de aprendizagem\n",
    "PatienceList = [40, 50]                                                           # lista com os valores de paciencia\n",
    "Epochs = [500, 600]                                                               # lista com os valores de epocas\n",
    "\n",
    "tuned_parameters ={                                                               # criacao do dicionario com os parametros para a busca em grade\n",
    "    \"solver\": SolverList,\n",
    "    \"batch_size\": BatchSizeList,\n",
    "    \"learning_rate_init\": LearningRateList,\n",
    "    \"n_iter_no_change\": PatienceList,\n",
    "    \"max_iter\": Epochs\n",
    "} \n",
    "cont = 0\n",
    "for i in top6_arquiteturas:                                                       # loop para criacao, busca em grade e treino das top6 configuracoes\n",
    "    cont = cont + 1\n",
    "    print(\"Executando configuração {} de 6\".format(cont))\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(i[\"disposicaoNeuronios\"]),     # criacao do modelo          \n",
    "                            activation=i[\"funcaoAtivacao\"], \n",
    "                            solver=i[\"hiperparametro\"], \n",
    "                            max_iter=i[\"epocas\"], \n",
    "                            verbose=False)\n",
    "    \n",
    "    clf = GridSearchCV(classifier, tuned_parameters, scoring=scoring, refit=\"f1_score\") # criacao da busca em grade\n",
    "    clf.fit(x_preditor, y_alvo)                                                   # treino usando os valores da busca em grade\n",
    "    \n",
    "    GridSearchList.append(clf)                                                    # insecao na lista para posterior avaliacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificando a mellhor solução\n",
    "\n",
    "Como resultado da busca em grande com validação cruzada 5-fold, identifique o modelo otimizado com melhor desempenho para o problema. Apresente claramente este modelo, seus parâmetros, hiperparâmetros otimizados e resultados para cada um dos folds avaliados. Esta é a melhor solução identificada em decorrência deste projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------- Parâmetros ------------------------------------------\n",
      "+---------+----------+----------------+--------+-----------+----------------------+-------------+\n",
      "| Camadas |  Função  | Hiperparametro | Épocas | Neurônios | Neurônios por camada | Categóricos |\n",
      "+---------+----------+----------------+--------+-----------+----------------------+-------------+\n",
      "|    1    | logistic |      adam      |  200   |     25    |          25          |     Não     |\n",
      "+---------+----------+----------------+--------+-----------+----------------------+-------------+\n",
      "\n",
      "------------------- Hiperparâmetros Otimizados ------------------\n",
      "+------------+--------------------+--------+-----------+--------+\n",
      "| Batch size | Learning rate init | Épocas | Paciência | Solver |\n",
      "+------------+--------------------+--------+-----------+--------+\n",
      "|   350000   |        0.01        |  500   |     40    |  adam  |\n",
      "+------------+--------------------+--------+-----------+--------+\n",
      "\n",
      "-------------------------------------------- K-Folds ----------------------------------------------\n",
      "+---------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| K-Folds | Config 1 | Config 2 | Config 3 | Config 4 | Config 5 | Config 6 | Config 7 | Config 8 |\n",
      "+---------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "|    1    | 0.09365  | 0.30904  | 0.10816  | 0.23042  | 0.09284  |  0.2556  | 0.09356  | 0.20684  |\n",
      "|    2    | 0.12084  | 0.31042  | 0.12058  | 0.32032  |  0.1301  | 0.28557  | 0.12798  | 0.28918  |\n",
      "|    3    | 0.11247  | 0.28435  | 0.13104  | 0.28347  | 0.11782  | 0.28329  | 0.11612  | 0.28352  |\n",
      "|    4    | 0.10398  | 0.25034  | 0.11768  | 0.23185  | 0.11849  | 0.23667  |  0.1079  | 0.24048  |\n",
      "|    5    | 0.10202  | 0.25268  | 0.12657  | 0.25541  | 0.10199  | 0.26992  | 0.12156  | 0.26059  |\n",
      "+---------+----------+----------+----------+----------+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "bestScore = 0.0\n",
    "bestEstimator = 0\n",
    "\n",
    "for idx, val in enumerate(GridSearchList):\n",
    "    if bestScore < val.best_score_:\n",
    "        bestScore = val.best_score_\n",
    "        bestEstimator = idx\n",
    "\n",
    "paramsTable = PrettyTable([\"Camadas\",\"Função\",                              # Criacao da tabela com os parametros\n",
    "                           \"Hiperparametro\", \"Épocas\", \n",
    "                           \"Neurônios\", \"Neurônios por camada\", \n",
    "                           \"Categóricos\"])\n",
    "paramsTable.add_row([top6_arquiteturas[bestEstimator][\"camadasOcultas\"], \n",
    "               top6_arquiteturas[bestEstimator][\"funcaoAtivacao\"], \n",
    "               top6_arquiteturas[bestEstimator][\"hiperparametro\"], \n",
    "               top6_arquiteturas[bestEstimator][\"epocas\"], \n",
    "               top6_arquiteturas[bestEstimator][\"neuronios\"], \n",
    "               top6_arquiteturas[bestEstimator][\"disposicaoNeuronios\"], \"Não\"])\n",
    "print(\"\\n------------------------------------------- Parâmetros ------------------------------------------\")\n",
    "print(paramsTable)\n",
    "\n",
    "hiperParamsTable = PrettyTable([\"Batch size\",\"Learning rate init\",          # Criacao da tabela com hiperparametros otimizados\n",
    "                                \"Épocas\", \"Paciência\", \n",
    "                                \"Solver\"])\n",
    "hiperParamsTable.add_row([GridSearchList[bestEstimator].best_params_[\"batch_size\"], \n",
    "               GridSearchList[bestEstimator].best_params_[\"learning_rate_init\"], \n",
    "               GridSearchList[bestEstimator].best_params_[\"max_iter\"], \n",
    "               GridSearchList[bestEstimator].best_params_[\"n_iter_no_change\"], \n",
    "               GridSearchList[bestEstimator].best_params_[\"solver\"]])\n",
    "print(\"\\n------------------- Hiperparâmetros Otimizados ------------------\")\n",
    "print(hiperParamsTable)\n",
    "\n",
    "kFoldsTable = PrettyTable([\"K-Folds\", \"Config 1\",\"Config 2\",               # Criacao da tabela com os resultados k-folds\n",
    "                           \"Config 3\", \"Config 4\", \"Config 5\",\n",
    "                          \"Config 6\", \"Config 7\", \"Config 8\"])\n",
    "for i in range(5):\n",
    "    kFoldsTable.add_row([i+1, round(GridSearchList[bestEstimator].cv_results_[\"split\"+str(i)+\"_test_f1_score\"][0], 5), \n",
    "                   round(GridSearchList[bestEstimator].cv_results_[\"split\"+str(i)+\"_test_f1_score\"][1], 5), \n",
    "                   round(GridSearchList[bestEstimator].cv_results_[\"split\"+str(i)+\"_test_f1_score\"][2], 5), \n",
    "                   round(GridSearchList[bestEstimator].cv_results_[\"split\"+str(i)+\"_test_f1_score\"][3], 5),\n",
    "                   round(GridSearchList[bestEstimator].cv_results_[\"split\"+str(i)+\"_test_f1_score\"][4], 5),\n",
    "                   round(GridSearchList[bestEstimator].cv_results_[\"split\"+str(i)+\"_test_f1_score\"][5], 5),\n",
    "                   round(GridSearchList[bestEstimator].cv_results_[\"split\"+str(i)+\"_test_f1_score\"][6], 5),\n",
    "                   round(GridSearchList[bestEstimator].cv_results_[\"split\"+str(i)+\"_test_f1_score\"][7], 5)])\n",
    "print(\"\\n-------------------------------------------- K-Folds ----------------------------------------------\")\n",
    "print(kFoldsTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empacotando a solução\n",
    "\n",
    "Suponha que você deve entregar este classificador ao órgão responsável por administrar o Roosevelt National Park. Para tanto, você deve fazer uma preparação do mesmo para utilização neste cenário. Uma vez que já identificou os melhores parâmetros e hiperparâmetros, o passo remanescente consiste em treinar o modelo com estes valores e todos os dados disponíveis, salvando o conjunto de pesos do modelo ao final para entrega ao cliente. Assim, finalize o projeto prático realizando tais passos.\n",
    "\n",
    "1. Consulte a documentação a seguir:\n",
    "https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "2. Treine o modelo com todos os dados\n",
    "3. Salve o modelo em disco  \n",
    "4. Construa uma rotina que recupere o modelo em disco  \n",
    "5. Mostre que a rotina é funcional, fazendo previsões com todos os elementos do dataset e exibindo uma matriz de confusão das mesmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criacao do modelo otimizado\n",
    "optimizedClassifier = MLPClassifier(hidden_layer_sizes=top6_arquiteturas[bestEstimator][\"disposicaoNeuronios\"],\n",
    "                        activation=top6_arquiteturas[bestEstimator][\"funcaoAtivacao\"], \n",
    "                        solver=GridSearchList[bestEstimator].best_params_[\"solver\"], \n",
    "                        max_iter=GridSearchList[bestEstimator].best_params_[\"max_iter\"],\n",
    "                        batch_size=GridSearchList[bestEstimator].best_params_[\"batch_size\"],\n",
    "                        learning_rate_init=GridSearchList[bestEstimator].best_params_[\"learning_rate_init\"],\n",
    "                        n_iter_no_change=GridSearchList[bestEstimator].best_params_[\"n_iter_no_change\"],\n",
    "                        verbose=False)\n",
    "\n",
    "# treino do modelo criado a cima\n",
    "optimizedClassifier.fit(x_preditor, y_alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLPClassifier.joblib']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persistencia do modelo em disco\n",
    "dump(optimizedClassifier, 'MLPClassifier.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136260  45738      0      0    159     12  19672]\n",
      " [ 75498 231128   8215    154   9203   6215    838]\n",
      " [    82   6435  27539   2593    131  11140      0]\n",
      " [     0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# Recuperação do modelo\n",
    "model = load('MLPClassifier.joblib') \n",
    "\n",
    "# Prevendo para todos os exemplos do dataset sem atributos categoricos\n",
    "y_test = model.predict(x_preditor)\n",
    "\n",
    "# matriz de confusao para os atributos do dataset\n",
    "print(confusion_matrix(y_test, y_alvo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
