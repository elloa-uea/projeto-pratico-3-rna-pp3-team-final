{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "PP3_3_Proposição_e_Avaliação_de_RNAs (5).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-IPPbpROBoi"
      },
      "source": [
        "## Redes Neurais Artificiais 2020.1\n",
        "\n",
        "**Disciplina**: Redes Neurais Artificiais 2020.1  \n",
        "**Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
        "**Github**: http://github.com/elloa  \n",
        "        \n",
        "\n",
        "Levando em conta a base de dados **_Forest Cover Type_**, esta terceira parte do Projeto Prático 3 diz respeito à proposição e avaliação de múltiplas redes neurais artificiais do tipo feedforward multilayer perceptron para o problema da classificação multi-classe da cobertura florestal em uma área do Roosevelt National Forest.\n",
        "\n",
        "## Testando Redes Neurais sem os Atributos Categórios\n",
        "\n",
        "1. Abra a base de dados em questão\n",
        "2. Elimine todas as colunas relativas aos atributos categóricos\n",
        "3. Armazene o atributo alvo em uma variável y e os atributos preditores em uma variável X\n",
        "4. Efetue uma partição holdout 70/30 com o sklearn, distribuindo os exemplos de maneira aleatória\n",
        "5. Efetue o escalonamento dos atributos\n",
        "\n",
        "### Escalonando os atributos\n",
        "\n",
        "O treinamento de uma rede neural artificial é mais eficiente quando os valores que lhes são fornecidos como entrada são pequenos, pois isto favorece a convergência. Isto é feito escalonando-se todos os atributos para o intervalo [0,1], mas precisa ser feito de maneira cautelosa, para que informações do conjunto de teste não sejam fornecidas no treinamento.\n",
        "\n",
        "Há duas estratégias para tal escalonamento: normalização e padronização. Ambas possuem características particulares, vantagens e limitações, como é possível ver aqui: https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
        "\n",
        "\n",
        "No nosso caso, vamos usar a padronização. Assim, com os atributos preditores do treinamento, isto é, X_train, deve-se subtrair a média e dividir pelo desvio padrão:\n",
        "\n",
        "X_train_std = (X_train - np.mean(X_train))/np.std(X_train)\n",
        "\n",
        "Em seguida, o mesmo deve ser feito com os atributos preditores do conjunto de testes, mas com padronização relativa ao conjunto de treinamento:\n",
        "\n",
        "X_test_std = (X_test - np.mean(X_train))/np.std(X_train)\n",
        "\n",
        "Se todo o conjunto X for utilizado na padronização, a rede neural receberá informações do conjunto de teste por meio da média e variância utilizada para preparar os dados de treinamento, o que não é desejável.\n",
        "\n",
        "\n",
        "### Continuando\n",
        "\n",
        "5. Treine uma rede neural multilayer perceptron para este problema com uma única camada e dez neurônios  \n",
        "    5.1 Utilize a função de ativação ReLU  \n",
        "    5.2 Utilize o solver Adam    \n",
        "    5.3 Imprima o passo a passo do treinamento    \n",
        "    5.4 Utilize o número máximo de épocas igual a 300  \n",
        "6. Com o modelo em questão, após o treinamento, apresente:  \n",
        "    6.1 Matriz de confusão para o conjunto de teste  \n",
        "    6.2 Acurácia  \n",
        "    6.3 F-Score  \n",
        "    6.4 Precisão  \n",
        "    6.5 Revocação  \n",
        "7. Repita o treinamento da mesma rede anterior sem imprimir o passo a passo (verbose False) por 100 vezes  \n",
        "    7.1 Cada uma destas repetições deve ser feita com uma nova partição Holdout  \n",
        "    7.2 Apresente a média e o desvio padrão da acurácia e do F-Score para o conjunto de treino  \n",
        "8. Repita por 100 vezes o treinamento desta mesma rede, mas utilizando o otimizador SGD  \n",
        "    8.1 Apresente a média e o desvio padrão da acurácia e do F-Score para o conjunto de treino  \n",
        "9. Houve influência da escolha do otimizador no desempenho da rede?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1laST-NOBok"
      },
      "source": [
        "## Reservado para a importação de bibliotecas\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objects as go\n",
        "import math\n",
        "import random\n",
        "from prettytable import PrettyTable  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG8mF9yzOynH",
        "outputId": "91336c1e-2b38-4f35-9820-e290af97c5aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Montagem do drive para o carregamento da base de dados por meio do google colab\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWmV3nMGO0FG"
      },
      "source": [
        "# Leitura do dataset covtype.csv\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/covtype.csv', sep=',')  # caso use google colab\n",
        "# df = pd.read_csv('./covtype.csv')                                               # caso faça localmente pelo jupyter"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-gwBze5Pt13"
      },
      "source": [
        "#### Preparação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8SieorfPuL-"
      },
      "source": [
        "# Eliminacao das colunas relativas aos atributos categoricos\n",
        "\n",
        "atributosCategoricos = []\n",
        "for i in range(40):                                                               # loop para preencher um vetor com os atributos categoricos\n",
        "  if i <=3:\n",
        "    atributosCategoricos.append(\"Wilderness_Area\"+str(i+1))\n",
        "  atributosCategoricos.append(\"Soil_Type\"+str(i+1))\n",
        "\n",
        "df = df.drop(columns=atributosCategoricos)                                        # delecao dos atributos categoricos"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiCQz7dNS6j7"
      },
      "source": [
        "y_alvo = df[\"Cover_Type\"]                                                         # separacao do atributo alvo\n",
        "x_preditor = df.drop(columns=[\"Cover_Type\"])                                      # separacao dos atributos preditores\n",
        "\n",
        "# Particao holdout para teste e treino\n",
        "x_train, x_test, y_train, y_test = train_test_split(                              # Criacao das particoes para treino e teste com o auxilio da biblioteca sklearn\n",
        "    x_preditor, y_alvo, test_size=0.3, train_size=0.7)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWq_wmUXP0I"
      },
      "source": [
        "# Escalonamento usando o metodo da padronização\n",
        "\n",
        "X_train_std = (x_train - np.mean(x_train))/np.std(x_train)                        # Escalonamento do conjunto de treino \n",
        "X_test_std = (x_test - np.mean(x_train))/np.std(x_train)                          # escalonamento do conjunto de teste levando em consideracao o conjunto de treino"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_laeWQ7PnVSQ"
      },
      "source": [
        "#### Criação e treinamento da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpQItHMXnVlm",
        "outputId": "f4b0f1cd-2928-4833-dc5e-b4e91b33671b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# criacao e treino da rede neural multilayer perceptron\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10),activation=\"relu\", solver=\"adam\", \n",
        "                    random_state=1, max_iter=300, \n",
        "                    verbose=True).fit(X_train_std, y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.92591820\n",
            "Iteration 2, loss = 0.70723923\n",
            "Iteration 3, loss = 0.68876529\n",
            "Iteration 4, loss = 0.68025876\n",
            "Iteration 5, loss = 0.67412817\n",
            "Iteration 6, loss = 0.66988273\n",
            "Iteration 7, loss = 0.66729017\n",
            "Iteration 8, loss = 0.66543756\n",
            "Iteration 9, loss = 0.66389991\n",
            "Iteration 10, loss = 0.66283764\n",
            "Iteration 11, loss = 0.66187217\n",
            "Iteration 12, loss = 0.66094189\n",
            "Iteration 13, loss = 0.66010021\n",
            "Iteration 14, loss = 0.65948238\n",
            "Iteration 15, loss = 0.65880299\n",
            "Iteration 16, loss = 0.65824638\n",
            "Iteration 17, loss = 0.65783200\n",
            "Iteration 18, loss = 0.65745867\n",
            "Iteration 19, loss = 0.65706568\n",
            "Iteration 20, loss = 0.65674884\n",
            "Iteration 21, loss = 0.65654777\n",
            "Iteration 22, loss = 0.65634320\n",
            "Iteration 23, loss = 0.65606280\n",
            "Iteration 24, loss = 0.65580755\n",
            "Iteration 25, loss = 0.65566029\n",
            "Iteration 26, loss = 0.65553128\n",
            "Iteration 27, loss = 0.65535162\n",
            "Iteration 28, loss = 0.65533766\n",
            "Iteration 29, loss = 0.65520549\n",
            "Iteration 30, loss = 0.65506871\n",
            "Iteration 31, loss = 0.65494528\n",
            "Iteration 32, loss = 0.65480403\n",
            "Iteration 33, loss = 0.65480128\n",
            "Iteration 34, loss = 0.65467683\n",
            "Iteration 35, loss = 0.65466316\n",
            "Iteration 36, loss = 0.65457588\n",
            "Iteration 37, loss = 0.65451867\n",
            "Iteration 38, loss = 0.65446719\n",
            "Iteration 39, loss = 0.65436617\n",
            "Iteration 40, loss = 0.65435116\n",
            "Iteration 41, loss = 0.65418188\n",
            "Iteration 42, loss = 0.65423767\n",
            "Iteration 43, loss = 0.65408752\n",
            "Iteration 44, loss = 0.65414321\n",
            "Iteration 45, loss = 0.65403263\n",
            "Iteration 46, loss = 0.65402633\n",
            "Iteration 47, loss = 0.65397122\n",
            "Iteration 48, loss = 0.65396586\n",
            "Iteration 49, loss = 0.65397393\n",
            "Iteration 50, loss = 0.65380552\n",
            "Iteration 51, loss = 0.65376219\n",
            "Iteration 52, loss = 0.65376900\n",
            "Iteration 53, loss = 0.65372769\n",
            "Iteration 54, loss = 0.65359641\n",
            "Iteration 55, loss = 0.65354191\n",
            "Iteration 56, loss = 0.65350415\n",
            "Iteration 57, loss = 0.65346324\n",
            "Iteration 58, loss = 0.65336840\n",
            "Iteration 59, loss = 0.65333349\n",
            "Iteration 60, loss = 0.65320343\n",
            "Iteration 61, loss = 0.65325899\n",
            "Iteration 62, loss = 0.65316957\n",
            "Iteration 63, loss = 0.65324429\n",
            "Iteration 64, loss = 0.65305313\n",
            "Iteration 65, loss = 0.65300422\n",
            "Iteration 66, loss = 0.65305227\n",
            "Iteration 67, loss = 0.65295476\n",
            "Iteration 68, loss = 0.65295369\n",
            "Iteration 69, loss = 0.65291362\n",
            "Iteration 70, loss = 0.65283776\n",
            "Iteration 71, loss = 0.65282394\n",
            "Iteration 72, loss = 0.65277810\n",
            "Iteration 73, loss = 0.65271065\n",
            "Iteration 74, loss = 0.65278881\n",
            "Iteration 75, loss = 0.65275695\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5N-0MrNoBE9",
        "outputId": "971efc64-809a-4afc-f666-8f5033cb1d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# obtencao das respostas para o conjunto de teste\n",
        "y_pred = clf.predict(X_test_std)\n",
        "\n",
        "# print da matriz de confusao\n",
        "matrizConfusao = confusion_matrix(y_test, y_pred)                                 # calculo da matriz de confusao\n",
        "\n",
        "table = PrettyTable([\"\",\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"])                       # Cria a tabela com as colunas de 1 a 7\n",
        "table.padding_width = 1\n",
        "\n",
        "for i in range(len(matrizConfusao)):                                              # loop para preencher a tabela com os dados\n",
        "  table.add_row(np.concatenate([[str(i+1)], matrizConfusao[i]]))\n",
        "\n",
        "print(\"----------------- MATRIZ DE CONFUSAO -----------------\")                   # print da matriz de confusao\n",
        "print(table)\n",
        "\n",
        "print(\"F1-SCORE:  {}\".format(round(f1_score(y_test, y_pred,                        # calculo do f-score\n",
        "                                           average='macro'), 4))) \n",
        "print(\"ACURACIA:  {}\".format(round(accuracy_score(y_test, y_pred), 4)))            # calculo da acuracia\n",
        "print(\"PRECISION: {}\".format(round(precision_score(y_test, y_pred,                # calculo da precisao\n",
        "                                                   average='macro'), 4)))\n",
        "print(\"RECALL:    {}\".format(round(recall_score(y_test, y_pred,                      # calculo da revocacao\n",
        "                                             average='macro'), 4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- MATRIZ DE CONFUSAO -----------------\n",
            "+---+-------+-------+------+-----+-----+------+------+\n",
            "|   |   1   |   2   |  3   |  4  |  5  |  6   |  7   |\n",
            "+---+-------+-------+------+-----+-----+------+------+\n",
            "| 1 | 43913 | 18200 |  8   |  0  |  8  |  9   | 1418 |\n",
            "| 2 | 15281 | 67963 | 1156 |  0  | 100 | 475  | 103  |\n",
            "| 3 |   0   |  1858 | 7512 | 131 |  0  | 1137 |  0   |\n",
            "| 4 |   0   |   4   | 375  | 271 |  0  | 145  |  0   |\n",
            "| 5 |   15  |  2547 |  46  |  0  | 323 |  10  |  0   |\n",
            "| 6 |   0   |  1463 | 2299 |  54 |  0  | 1411 |  0   |\n",
            "| 7 |  2843 |   28  |  0   |  0  |  0  |  0   | 3198 |\n",
            "+---+-------+-------+------+-----+-----+------+------+\n",
            "F1-SCORE:  0.5288\n",
            "ACURACIA:  0.7148\n",
            "PRECISION: 0.6527\n",
            "RECALL:    0.4919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aLK7ye3270j",
        "outputId": "2f221789-6a94-415e-eb99-b3603c8aa610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "f1scores = np.zeros(100)\n",
        "acuracias = np.zeros(100)\n",
        "\n",
        "for i in range (100):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(                              # Criacao das particoes para treino e teste com o auxilio da biblioteca sklearn\n",
        "    x_preditor, y_alvo, test_size=0.3, train_size=0.7)\n",
        "  \n",
        "  X_train_std = (x_train - np.mean(x_train))/np.std(x_train)                        # Escalonamento do conjunto de treino \n",
        "  X_test_std = (x_test - np.mean(x_train))/np.std(x_train)  \n",
        "\n",
        "  clf = MLPClassifier(hidden_layer_sizes=(10),activation=\"relu\", solver=\"adam\",     # criacao da rede neural multilayer perceptron\n",
        "                      max_iter=300, \n",
        "                      verbose=False).fit(X_train_std, y_train)\n",
        "\n",
        "  clf.fit(X_train_std, y_train)                                                     # treino da rede neural \n",
        "\n",
        "  y_pred = clf.predict(X_test_std)                                                  # predicao para o conjuto de teste escalonado\n",
        "\n",
        "  f1scores[i] = f1_score(y_test, y_pred, average='macro')                           # armazenamento do valor de f-score\n",
        "  acuracias[i] = accuracy_score(y_test, y_pred)                                     # armazenamento do valor de acuracia\n",
        "\n",
        "# calculo das medias e desvios padrao dos dados de acuracia e f-score\n",
        "print(\"Média de acurácia:      {}\".format(round(acuracias.mean(), 5)))\n",
        "print(\"Desvio Padrão acurácia: {}\".format(round(acuracias.std(), 5)))\n",
        "print(\"Média de F-Score:       {}\".format(round(f1scores.mean(), 5)))\n",
        "print(\"Desvio Padrão F-Score:  {}\".format(round(f1scores.std(), 5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média de acurácia:      0.71554\n",
            "Desvio Padrão acurácia: 0.0021\n",
            "Média de F-Score:       0.51661\n",
            "Desvio Padrão F-Score:  0.01065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKPt8TtY5wc6"
      },
      "source": [
        "#### Treinamento da rede neural anterior levando em consideracao o **SOLVER** sendo `SGD`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Y3YAel6syn",
        "outputId": "f3b830fc-b7af-4996-b4db-beb069eec364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "f1scores = np.zeros(100)\n",
        "acuracias = np.zeros(100)\n",
        "\n",
        "for i in range (100):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(                              # Criacao das particoes para treino e teste com o auxilio da biblioteca sklearn\n",
        "    x_preditor, y_alvo, test_size=0.3, train_size=0.7)\n",
        "  \n",
        "  X_train_std = (x_train - np.mean(x_train))/np.std(x_train)                        # Escalonamento do conjunto de treino \n",
        "  X_test_std = (x_test - np.mean(x_train))/np.std(x_train)  \n",
        "\n",
        "  clf = MLPClassifier(hidden_layer_sizes=(10),activation=\"relu\", solver=\"sgd\", \n",
        "                      max_iter=300, \n",
        "                      verbose=False).fit(X_train_std, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test_std)\n",
        "\n",
        "  f1scores[i] = f1_score(y_test, y_pred, average='macro')\n",
        "  acuracias[i] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"media acuracia:          {}\".format(round(acuracias.mean(), 5)))\n",
        "print(\"desvio padrao acuracia:  {}\".format(round(acuracias.std(), 5)))\n",
        "print(\"media f-score:           {}\".format(round(f1scores.mean(), 5)))\n",
        "print(\"desvio padrao f-score:   {}\".format(round(f1scores.std(), 5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "media acuracia:          0.7147\n",
            "desvio padrao acuracia:  0.00301\n",
            "media f-score:           0.48194\n",
            "desvio padrao f-score:   0.01792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EspDY_sJRlCP"
      },
      "source": [
        "### Houve influência da escolha do otimizador no desempenho da rede?\n",
        "\n",
        "Sim, como foi visto a partir dos dados de media e desvio padrão sobre a acuracia e o F-Score com os hiperparametros solver `adam e sgd`. O modelo que teve o solver sendo adam se saiu levemente melhor, obtendo uma maior pontuação para media de f-score e ligeiramente melhor para media de acuracia tambem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4P1gJcaOBon"
      },
      "source": [
        "## Discussão\n",
        "\n",
        "Nos passos anteriores, você avaliou o desempenho de uma única rede neural que contém os seguintes parâmetros: uma única camada oculta com 10 neurônios e função de ativação ReLU. O otimizador utilizado, quer seja SGD ou ADAM, trata-se do algoritmo para aproximar o gradiente do erro. Neste sentido, a escolha do otimizador é um hiperparâmetro, pois diz respeito a como a rede neural definida previamente atuará \"em tempo de execução\"  durante o processo de treinamento. Também são hiperparâmetros a quantidade de épocas, a taxa de aprendizado inicial, dentre outros.\n",
        "\n",
        "Cabe alientar também que você efetuou o treinamento desta rede por 100 vezes e apresentou os resultados em termos de média +- desvio padrão. Lembre-se que em uma rede neural há a inicialização aleatória de pesos e, em consequência, o desempenho delas está sujeito à uma flutuação estocástica. A execução destas múltiplas vezes faz com que eliminemos algum viés introduzido por uma boa ou má \"sorte\" na escolha de pesos no caso de uma única execução.\n",
        "\n",
        "## Propondo Novas Arquiteturas\n",
        "\n",
        "Variando  os parâmetros (uma ou duas camadas ocultas, com diferente números de neurônios em cada uma delas e a função de ativação) e o hiperparâmetros solver (Adam ou SGD) e o número de épocas (100,150 e 200), atenda ao que se pede:\n",
        "\n",
        "1. Proponha 10 arquiteturas distintas de RNAs para o problema em questão, à sua escolha\n",
        "2. Avalie cada uma das arquiteturas perante todos os hiperparâmetros apresentados por 100 vezes\n",
        "3. Como resultado da avaliação, apresente:  \n",
        "    3.1 Top-3 melhores redes no tocante à F-Score e Acurácia  \n",
        "    3.2 Repetição em que houve o melhor desempenho de cada uma dessas redes: ilustre tp, tf, fp e fn  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDMNIkVFcsCb"
      },
      "source": [
        "#### Criação das configuracoes para as redes neurais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RN7_8M9WApz"
      },
      "source": [
        "funcaoAtivação = [\"identity\", \"logistic\", \"tanh\", \"relu\"]                         # declaracao do vetor com os tipos de funcao de ativacao\n",
        "hiperParametro = [\"adam\", \"sgd\"]                                                  # declaracao do vetor com o tipo do hiperparametro solver\n",
        "epocas = [100, 150, 200]                                                          # declaracao do vetor com a quanitdade de epocas\n",
        "camadas = [1, 2]\n",
        "configuracoes = []                                                                # declaracao do vetor que armazenara as configuracoes geradas\n",
        "\n",
        "for i in range (10):                                                              # loop para gerar aleatoriamente as configuracoes (dentro do especificado)\n",
        "  tipoEpoca = random.randrange(1, 1000000, 1)%3\n",
        "  tipoHiperParametro = random.randrange(1, 1000000, 1)%2\n",
        "  tipoFuncaoAtivacao = random.randrange(1, 1000000, 1)%4\n",
        "  xqtdCamadas = random.randrange(1, 1000000, 1)%2\n",
        "  qtdNeuronios = random.randrange(1, 20, 1)\n",
        "  \n",
        "  aux = random.randrange(1, qtdNeuronios, 1)                                      # variavel auxiliar\n",
        "  disposicaoNeuronios = qtdNeuronios if camadas[xqtdCamadas]==1 else (aux, qtdNeuronios-aux) # disposicao dos neuronios nas 2 camadas ocultas\n",
        "\n",
        "  configuracoes.append({                                                          # armazenamento das configuracoes geradas\n",
        "    \"camadasOcultas\": camadas[xqtdCamadas],\n",
        "    \"funcaoAtivacao\": funcaoAtivação[tipoFuncaoAtivacao],\n",
        "    \"hiperparametro\": hiperParametro[tipoHiperParametro],\n",
        "    \"epocas\": epocas[tipoEpoca],\n",
        "    \"neuronios\": qtdNeuronios,\n",
        "    \"disposicaoNeuronios\": disposicaoNeuronios\n",
        "  })"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NtJRzhVgnH_"
      },
      "source": [
        "#### Apresentação das configuracoes de redes geradas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTvv7pMcgmvQ",
        "outputId": "31160e90-89d9-4aef-ffa6-b4c4186e182c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "table = PrettyTable([\"Quantidade de camadas\",\"Função de ativação\",                  # Criacao da tabela\n",
        "                      \"Hiperparametro\", \"Quantidade de épocas\", \n",
        "                      \"Quantidade de neurônios\", \"Disposição dos neurônios\"])        \n",
        "\n",
        "table.padding_width = 1\n",
        "\n",
        "for i in configuracoes:                                                           # loop para preencher a tabela com os dados\n",
        "  table.add_row([i[\"camadasOcultas\"], i[\"funcaoAtivacao\"], i[\"hiperparametro\"],\n",
        "                i[\"epocas\"], i[\"neuronios\"], i[\"disposicaoNeuronios\"]])\n",
        "\n",
        "print(\"----------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS -----------------------------------------------------\")                   # print da matriz de confusao\n",
        "print(table)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS -----------------------------------------------------\n",
            "+-----------------------+--------------------+----------------+----------------------+-------------------------+--------------------------+\n",
            "| Quantidade de camadas | Função de ativação | Hiperparametro | Quantidade de épocas | Quantidade de neurônios | Disposição dos neurônios |\n",
            "+-----------------------+--------------------+----------------+----------------------+-------------------------+--------------------------+\n",
            "|           1           |        tanh        |      sgd       |         150          |            11           |            11            |\n",
            "|           1           |        tanh        |      adam      |         100          |            8            |            8             |\n",
            "|           1           |        tanh        |      sgd       |         150          |            13           |            13            |\n",
            "|           1           |      logistic      |      adam      |         200          |            15           |            15            |\n",
            "|           1           |      identity      |      adam      |         200          |            12           |            12            |\n",
            "|           1           |      identity      |      sgd       |         100          |            11           |            11            |\n",
            "|           2           |      logistic      |      sgd       |         200          |            9            |          (4, 5)          |\n",
            "|           2           |      identity      |      adam      |         200          |            2            |          (1, 1)          |\n",
            "|           2           |      logistic      |      sgd       |         150          |            12           |          (6, 6)          |\n",
            "|           1           |      logistic      |      sgd       |         150          |            11           |            11            |\n",
            "+-----------------------+--------------------+----------------+----------------------+-------------------------+--------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB8xFSedmtjt"
      },
      "source": [
        "#### Treinamento das redes com os parametros listados acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlfNJpTNmsh9"
      },
      "source": [
        "melhoresMatrizes = []\n",
        "desempenhoGeral = []\n",
        "melhorDesempenhoIndividual = []\n",
        "cont=0\n",
        "for i in configuracoes:\n",
        "    cont+=1\n",
        "    f1scores = np.zeros(10)\n",
        "    acuracias = np.zeros(10)\n",
        "\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(i[\"disposicaoNeuronios\"]),\n",
        "                            activation=i[\"funcaoAtivacao\"], \n",
        "                            solver=i[\"hiperparametro\"], \n",
        "                            max_iter=i[\"epocas\"], \n",
        "                            verbose=False)\n",
        "\n",
        "    for j in range(10):\n",
        "        x_train, x_test, y_train, y_test = train_test_split(\n",
        "            x_preditor, y_alvo, test_size=0.3, train_size=0.7)\n",
        "        \n",
        "        X_train_std = (x_train - np.mean(x_train))/np.std(x_train)\n",
        "        X_test_std = (x_test - np.mean(x_train))/np.std(x_train)\n",
        "\n",
        "        clf.fit(X_train_std, y_train)\n",
        "\n",
        "        y_pred = clf.predict(X_test_std)\n",
        "\n",
        "        f1scores[j] = f1_score(y_test, y_pred, average='macro')\n",
        "        acuracias[j] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        if j == 0:\n",
        "          melhorDesempenhoIndividual.append({\n",
        "              \"acuracia\": acuracias[j],\n",
        "              \"fscore\": f1scores[j]\n",
        "          })\n",
        "          melhoresMatrizes.append(confusion_matrix(y_test, y_pred))\n",
        "        else:\n",
        "          if acuracias[j] >= melhorDesempenhoIndividual[cont-1][\"acuracia\"]:\n",
        "            if  acuracias[j] == melhorDesempenhoIndividual[cont-1][\"acuracia\"]:\n",
        "              if f1scores[j] > melhorDesempenhoIndividual[cont-1][\"fscore\"]:\n",
        "                melhorDesempenhoIndividual[cont-1][\"fscore\"] = f1scores[j]\n",
        "                melhorDesempenhoIndividual[cont-1][\"acuracia\"] = acuracias[j]\n",
        "                melhoresMatrizes[cont-1] = confusion_matrix(y_test, y_pred)\n",
        "            else:\n",
        "              melhorDesempenhoIndividual[cont-1][\"fscore\"] = f1scores[j]\n",
        "              melhorDesempenhoIndividual[cont-1][\"acuracia\"] = acuracias[j]\n",
        "              melhoresMatrizes[cont-1] = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    desempenhoGeral.append({\n",
        "        \"configuracao\": cont,\n",
        "        \"media\": round(acuracias.mean(), 5),\n",
        "        \"fscore\": round(f1scores.mean(), 5)\n",
        "    })"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On4g--vkjCKW",
        "outputId": "66975c93-ec6f-41a5-f44e-7387db18fd05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# desempenhoGeral\n",
        "sorted_list = sorted(desempenhoGeral, key=lambda k: k['media']) \n",
        "primeiro = sorted_list[9]\n",
        "segundo = sorted_list[8]\n",
        "terceiro = sorted_list[7]\n",
        "\n",
        "table = PrettyTable([\"\", \"Camadas\",\"Função de ativação\",                  # Criacao da tabela\n",
        "                      \"Hiperparametro\", \"Épocas\", \n",
        "                      \"Quantidade de neurônios\", \"Disposição dos neurônios\", \n",
        "                     \"Média acuracia\", \"Média F-Score\"])        \n",
        "\n",
        "table.padding_width = 1\n",
        "\n",
        "# preenchimento dos dados da table (3 melhores desempenhos)\n",
        "table.add_row([\"1°\", configuracoes[primeiro[\"configuracao\"]-1][\"camadasOcultas\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               primeiro[\"media\"], primeiro[\"fscore\"]])\n",
        "table.add_row([\"2°\", configuracoes[segundo[\"configuracao\"]-1][\"camadasOcultas\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               segundo[\"media\"], segundo[\"fscore\"]])\n",
        "table.add_row([\"3°\", configuracoes[terceiro[\"configuracao\"]-1][\"camadasOcultas\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               terceiro[\"media\"], terceiro[\"fscore\"]])\n",
        "\n",
        "print(\"---------------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ----------------------------------------------------------\")                   # print da matriz de confusao\n",
        "print(table)\n",
        "\n",
        "# Print das matrizes de confusao das melhores configuracões\n",
        "print(\"------------- Primeiro Colocado ------------\")\n",
        "print(melhoresMatrizes[primeiro[\"configuracao\"]-1])\n",
        "\n",
        "print(\"\\n------------- Segundo Colocado -------------\")\n",
        "print(melhoresMatrizes[segundo[\"configuracao\"]-1])\n",
        "\n",
        "print(\"\\n------------- Terceiro Colocado ------------\")\n",
        "print(melhoresMatrizes[terceiro[\"configuracao\"]-1])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ----------------------------------------------------------\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "|    | Camadas | Função de ativação | Hiperparametro | Épocas | Quantidade de neurônios | Disposição dos neurônios | Média acuracia | Média F-Score |\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "| 1° |    1    |      logistic      |      adam      |  200   |            15           |            15            |    0.73191     |    0.54205    |\n",
            "| 2° |    1    |        tanh        |      sgd       |  150   |            13           |            13            |    0.72023     |    0.47931    |\n",
            "| 3° |    1    |        tanh        |      sgd       |  150   |            11           |            11            |    0.71824     |    0.47116    |\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "------------- Primeiro Colocado ------------\n",
            "[[46269 16352     4     0    45    35   994]\n",
            " [14522 68695  1026     0   120   460   122]\n",
            " [    0  1889  7998    33     0   690     0]\n",
            " [    0     5   499   288     0    47     0]\n",
            " [   31  2405    49     0   309    24     0]\n",
            " [    6  1425  2648    28     0  1098     0]\n",
            " [ 2505    43     0     0     0     0  3640]]\n",
            "\n",
            "------------- Segundo Colocado -------------\n",
            "[[45138 16941     7     1    14    24  1225]\n",
            " [14813 68810   902     6    76   454    41]\n",
            " [    0  1889  7956    68     0   817     0]\n",
            " [    0    10   527   186     0   137     0]\n",
            " [   30  2428    26     0   314    50     0]\n",
            " [    1  1596  2691    17     0   994     0]\n",
            " [ 3155    28     0     0     0     0  2932]]\n",
            "\n",
            "------------- Terceiro Colocado ------------\n",
            "[[44051 18009     1     0     0    23  1103]\n",
            " [13904 70014  1003     0     3   323    29]\n",
            " [    0  2151  8164   106     0   389     0]\n",
            " [    0    10   544   263     0    41     0]\n",
            " [   52  2810    16     0     8     0     0]\n",
            " [    0  1618  2919    28     0   650     0]\n",
            " [ 3340    28     0     0     0     0  2704]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olxa7kX2OBoq"
      },
      "source": [
        "## Estimando o número de neurônios\n",
        "\n",
        "Um dos problemas de pesquisa com redes neurais artificiais consiste na determinação do número de neurônios em sua arquitetura. Embora não seja possível definir a priori qual rede neural é adequada para um problema, pois isto só é possível mediante uma busca exaustiva, há regras na literatura que sugerem o número de neurônios escondidos, tal como a regra da Pirâmide Geométrica, dada a seguir:\n",
        "\n",
        "$$N_h = \\alpha \\cdot \\sqrt{N_i \\cdot N_o},$$\n",
        "\n",
        "em que $N_h$ é o número de neurônios ocultos (a serem distribuídos em uma ou duas camadas ocultas), $N_i$ é o número de neurônios na camada de entrada e $N_o$ é o número de neurônios na camada de saída. \n",
        "\n",
        "1. Consulte a documentação da classe MLPClassifier (disponível em https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) e obtenha os valores de $N_i$ e $N_h$.\n",
        "2. Teste os valores de $\\alpha$ como sendo iguais a $0.5$, $2$ e $3$.\n",
        "3. Proponha pelo menos 30 redes neurais segundo a regra da pirâmide geométrica e teste-as nos mesmos termos estabelecidos anterioremente  (solver, épocas, etc.)  \n",
        "    3.1 Apresente as top-3 melhores redes no tocante à F-Score e Acurácia  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1eqx4_J_qYz"
      },
      "source": [
        "#### Como o texto acima indica e segundo a documentação da biblioteca `sklearn.neural_network.MLPClassifier` informa, os valores para **Ni, No** estão relacionados a quantidade de atributos preditores e quantidade de classes respectivamente. Sendo assim ambos correspondem, respectivamente a x e 7.\n",
        "\n",
        "\n",
        "### Criacao das 30 configurações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLdvc6AiDutC"
      },
      "source": [
        "# Atribuicao dos parametros da regra da piramide geometrica\n",
        "Ni = 10\n",
        "No = 7\n",
        "alpha = [0.5, 2, 3]\n",
        "Nh = [] \n",
        "\n",
        "for a in alpha:\n",
        "  Nh.append(int(a*math.sqrt(Ni*No))) \n",
        "\n",
        "# print(Nh)\n",
        "# proposicao das 30 redes neurais usando a regra da pirameide para a quantidade de neuronios\n",
        "funcaoAtivação = [\"identity\", \"logistic\", \"tanh\", \"relu\"]                         # declaracao do vetor com os tipos de funcao de ativacao\n",
        "hiperParametro = [\"adam\", \"sgd\"]                                                  # declaracao do vetor com o tipo do hiperparametro solver\n",
        "epocas = [100, 150, 200]                                                          # declaracao do vetor com a quanitdade de epocas\n",
        "camadas = [1, 2]\n",
        "configuracoes = []                                                                # declaracao do vetor que armazenara as configuracoes geradas\n",
        "\n",
        "for i in range (30):                                                              # loop para gerar aleatoriamente as configuracoes (dentro do especificado)\n",
        "  tipoEpoca = random.randrange(1, 1000000, 1)%3\n",
        "  tipoHiperParametro = random.randrange(1, 1000000, 1)%2\n",
        "  tipoFuncaoAtivacao = random.randrange(1, 1000000, 1)%4\n",
        "  xqtdCamadas = random.randrange(1, 1000000, 1)%2\n",
        "  qtdNeuronios = random.randrange(1, 1000000, 1)%3\n",
        "  \n",
        "  aux = random.randrange(1, Nh[qtdNeuronios], 1)                                      # variavel auxiliar\n",
        "  disposicaoNeuronios = Nh[qtdNeuronios] if camadas[xqtdCamadas]==1 else (aux, Nh[qtdNeuronios]-aux) # disposicao dos neuronios nas 2 camadas ocultas\n",
        "\n",
        "  configuracoes.append({                                                          # armazenamento das configuracoes geradas\n",
        "    \"camadasOcultas\": camadas[xqtdCamadas],\n",
        "    \"funcaoAtivacao\": funcaoAtivação[tipoFuncaoAtivacao],\n",
        "    \"hiperparametro\": hiperParametro[tipoHiperParametro],\n",
        "    \"epocas\": epocas[tipoEpoca],\n",
        "    \"neuronios\": Nh[qtdNeuronios],\n",
        "    \"disposicaoNeuronios\": disposicaoNeuronios\n",
        "  })"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhDKUkj3H6EV"
      },
      "source": [
        "#### Configuracao das 30 redes propostas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnq8PjHrH5ru",
        "outputId": "8e5f93f7-d9f3-4712-f55e-67f54a54aa1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "table = PrettyTable([\"Camadas\",\"Função de ativação\",                  # Criacao da tabela\n",
        "                      \"Hiperparametro\", \"Épocas\", \n",
        "                      \"Quantidade de neurônios\", \"Disposição dos neurônios\"])        \n",
        "\n",
        "table.padding_width = 1\n",
        "\n",
        "for i in configuracoes:                                                           # loop para preencher a tabela com os dados\n",
        "  table.add_row([i[\"camadasOcultas\"], i[\"funcaoAtivacao\"], i[\"hiperparametro\"],\n",
        "                i[\"epocas\"], i[\"neuronios\"], i[\"disposicaoNeuronios\"]])\n",
        "\n",
        "print(\"--------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ---------------------------------------\")                   # print da matriz de confusao\n",
        "print(table)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ---------------------------------------\n",
            "+---------+--------------------+----------------+--------+-------------------------+--------------------------+\n",
            "| Camadas | Função de ativação | Hiperparametro | Épocas | Quantidade de neurônios | Disposição dos neurônios |\n",
            "+---------+--------------------+----------------+--------+-------------------------+--------------------------+\n",
            "|    1    |      logistic      |      adam      |  150   |            4            |            4             |\n",
            "|    1    |      identity      |      adam      |  200   |            4            |            4             |\n",
            "|    1    |      identity      |      sgd       |  150   |            4            |            4             |\n",
            "|    2    |        tanh        |      adam      |  150   |            16           |         (4, 12)          |\n",
            "|    2    |      logistic      |      sgd       |  200   |            25           |         (6, 19)          |\n",
            "|    1    |      logistic      |      sgd       |  100   |            25           |            25            |\n",
            "|    1    |        relu        |      adam      |  200   |            16           |            16            |\n",
            "|    2    |      identity      |      sgd       |  150   |            16           |         (13, 3)          |\n",
            "|    2    |        relu        |      sgd       |  150   |            4            |          (1, 3)          |\n",
            "|    1    |      logistic      |      adam      |  200   |            25           |            25            |\n",
            "|    2    |        tanh        |      sgd       |  100   |            4            |          (2, 2)          |\n",
            "|    2    |        tanh        |      sgd       |  150   |            4            |          (3, 1)          |\n",
            "|    1    |        relu        |      sgd       |  100   |            25           |            25            |\n",
            "|    2    |        relu        |      sgd       |  200   |            25           |         (13, 12)         |\n",
            "|    2    |      logistic      |      adam      |  150   |            4            |          (3, 1)          |\n",
            "|    1    |        tanh        |      sgd       |  200   |            25           |            25            |\n",
            "|    2    |        relu        |      sgd       |  150   |            4            |          (1, 3)          |\n",
            "|    2    |        tanh        |      adam      |  200   |            16           |         (3, 13)          |\n",
            "|    1    |        relu        |      sgd       |  200   |            25           |            25            |\n",
            "|    1    |        relu        |      adam      |  100   |            25           |            25            |\n",
            "|    1    |      identity      |      sgd       |  100   |            25           |            25            |\n",
            "|    1    |        relu        |      adam      |  200   |            4            |            4             |\n",
            "|    2    |      identity      |      sgd       |  200   |            25           |         (1, 24)          |\n",
            "|    2    |        tanh        |      adam      |  200   |            25           |         (9, 16)          |\n",
            "|    1    |      logistic      |      sgd       |  150   |            25           |            25            |\n",
            "|    1    |      logistic      |      adam      |  150   |            25           |            25            |\n",
            "|    1    |        relu        |      adam      |  100   |            4            |            4             |\n",
            "|    1    |        tanh        |      sgd       |  150   |            16           |            16            |\n",
            "|    1    |      identity      |      adam      |  200   |            4            |            4             |\n",
            "|    2    |        tanh        |      adam      |  100   |            16           |         (15, 1)          |\n",
            "+---------+--------------------+----------------+--------+-------------------------+--------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPNgjIQtIYAx"
      },
      "source": [
        "#### Criação e treinamento das redes neurais propostas acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbpG5lbFIXWy"
      },
      "source": [
        "ranking = []\n",
        "cont=0\n",
        "for i in configuracoes:\n",
        "    cont+=1\n",
        "    f1scores = np.zeros(10)\n",
        "    acuracias = np.zeros(10)\n",
        "    for j in range(100):\n",
        "        x_train, x_test, y_train, y_test = train_test_split(\n",
        "            x_preditor, y_alvo, test_size=0.3, train_size=0.7)\n",
        "        \n",
        "        X_train_std = (x_train - np.mean(x_train))/np.std(x_train)\n",
        "        X_test_std = (x_test - np.mean(x_train))/np.std(x_train)\n",
        "\n",
        "        clf = MLPClassifier(hidden_layer_sizes=(i[\"disposicaoNeuronios\"]),\n",
        "                            activation=i[\"funcaoAtivacao\"], \n",
        "                            solver=i[\"hiperparametro\"], \n",
        "                            max_iter=i[\"epocas\"], \n",
        "                            verbose=False).fit(X_train_std, y_train)\n",
        "\n",
        "        y_pred = clf.predict(X_test_std)\n",
        "\n",
        "        f1scores[i] = f1_score(y_test, y_pred, average='micro')\n",
        "        acuracias[i] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    ranking.append({\n",
        "        \"configuracao\": cont,\n",
        "        \"media\": acuracias.mean(),\n",
        "        \"fscore\": f1scores.mean()\n",
        "    })\n",
        "\n",
        "print(ranking)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UehBG1nOBos"
      },
      "source": [
        "## Testando as Redes Neurais com Atributos Categóricos\n",
        "\n",
        "1. Considere as 6 redes neurais obtidas nos dois top-3 anteriores (arquiteturas próprias e regra da pirâmide geométrica)\n",
        "2. Com todos os atributos preditores da base de dados original, incluindo os categóricos, treine e teste estas mesmas redes por 100 repetições  \n",
        "    2.1 Considere o melhor otimizador para cada uma delas  \n",
        "    2.2 Faça uso de 200 épocas para treinamento  \n",
        "    2.2 Apresente os resultados de acurácia e F-Score em termos da média +- dp para cada arquitetura\n",
        "3. Apresente o gráfico boxplot para o F-Score das 6 arquiteturas perante as 100 repetições"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEvL8grsOBot"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B7-fC8IOBov"
      },
      "source": [
        "## Considerações Parciais\n",
        "\n",
        "1. É possível identificar uma rede com desempenho superior às demais?\n",
        "2. Qual estratégia mostrou-se mais producente para a obtenção de boas arquiteturas (Estratégia Própria ou Pirâmide Geométrica)? Por quê?\n",
        "3. Considerar os atributos categóricos trouxe melhorias? Justifique.\n",
        "4. Um número maior de épocas trouxe melhorias?\n",
        "5. Qual a maior dificuldade de resolução do problema proposto perante as RNAs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItP1HTw8OBow"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}