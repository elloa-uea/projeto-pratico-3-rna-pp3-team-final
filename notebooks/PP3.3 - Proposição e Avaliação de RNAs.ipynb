{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "PP3.3 - Proposição e Avaliação de RNAs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-IPPbpROBoi"
      },
      "source": [
        "## Redes Neurais Artificiais 2020.1\n",
        "\n",
        "**Disciplina**: Redes Neurais Artificiais 2020.1  \n",
        "**Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
        "**Github**: http://github.com/elloa  \n",
        "        \n",
        "\n",
        "Levando em conta a base de dados **_Forest Cover Type_**, esta terceira parte do Projeto Prático 3 diz respeito à proposição e avaliação de múltiplas redes neurais artificiais do tipo feedforward multilayer perceptron para o problema da classificação multi-classe da cobertura florestal em uma área do Roosevelt National Forest.\n",
        "\n",
        "## Testando Redes Neurais sem os Atributos Categórios\n",
        "\n",
        "1. Abra a base de dados em questão\n",
        "2. Elimine todas as colunas relativas aos atributos categóricos\n",
        "3. Armazene o atributo alvo em uma variável y e os atributos preditores em uma variável X\n",
        "4. Efetue uma partição holdout 70/30 com o sklearn, distribuindo os exemplos de maneira aleatória\n",
        "5. Efetue o escalonamento dos atributos\n",
        "\n",
        "### Escalonando os atributos\n",
        "\n",
        "O treinamento de uma rede neural artificial é mais eficiente quando os valores que lhes são fornecidos como entrada são pequenos, pois isto favorece a convergência. Isto é feito escalonando-se todos os atributos para o intervalo [0,1], mas precisa ser feito de maneira cautelosa, para que informações do conjunto de teste não sejam fornecidas no treinamento.\n",
        "\n",
        "Há duas estratégias para tal escalonamento: normalização e padronização. Ambas possuem características particulares, vantagens e limitações, como é possível ver aqui: https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
        "\n",
        "\n",
        "No nosso caso, vamos usar a padronização. Assim, com os atributos preditores do treinamento, isto é, X_train, deve-se subtrair a média e dividir pelo desvio padrão:\n",
        "\n",
        "X_train_std = (X_train - np.mean(X_train))/np.std(X_train)\n",
        "\n",
        "Em seguida, o mesmo deve ser feito com os atributos preditores do conjunto de testes, mas com padronização relativa ao conjunto de treinamento:\n",
        "\n",
        "X_test_std = (X_test - np.mean(X_train))/np.std(X_train)\n",
        "\n",
        "Se todo o conjunto X for utilizado na padronização, a rede neural receberá informações do conjunto de teste por meio da média e variância utilizada para preparar os dados de treinamento, o que não é desejável.\n",
        "\n",
        "\n",
        "### Continuando\n",
        "\n",
        "5. Treine uma rede neural multilayer perceptron para este problema com uma única camada e dez neurônios  \n",
        "    5.1 Utilize a função de ativação ReLU  \n",
        "    5.2 Utilize o solver Adam    \n",
        "    5.3 Imprima o passo a passo do treinamento    \n",
        "    5.4 Utilize o número máximo de épocas igual a 300  \n",
        "6. Com o modelo em questão, após o treinamento, apresente:  \n",
        "    6.1 Matriz de confusão para o conjunto de teste  \n",
        "    6.2 Acurácia  \n",
        "    6.3 F-Score  \n",
        "    6.4 Precisão  \n",
        "    6.5 Revocação  \n",
        "7. Repita o treinamento da mesma rede anterior sem imprimir o passo a passo (verbose False) por 100 vezes  \n",
        "    7.1 Cada uma destas repetições deve ser feita com uma nova partição Holdout  \n",
        "    7.2 Apresente a média e o desvio padrão da acurácia e do F-Score para o conjunto de treino  \n",
        "8. Repita por 100 vezes o treinamento desta mesma rede, mas utilizando o otimizador SGD  \n",
        "    8.1 Apresente a média e o desvio padrão da acurácia e do F-Score para o conjunto de treino  \n",
        "9. Houve influência da escolha do otimizador no desempenho da rede?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1laST-NOBok"
      },
      "source": [
        "## Reservado para a importação de bibliotecas\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objects as go\n",
        "import math\n",
        "import random\n",
        "from prettytable import PrettyTable  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG8mF9yzOynH",
        "outputId": "c6a42118-b2fc-47a9-dcef-750575cf3e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Montagem do drive para o carregamento da base de dados por meio do google colab\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWmV3nMGO0FG"
      },
      "source": [
        "# Leitura do dataset covtype.csv\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/covtype.csv', sep=',')  # caso use google colab\n",
        "# df = pd.read_csv('./covtype.csv')                                               # caso faça localmente pelo jupyter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-gwBze5Pt13"
      },
      "source": [
        "#### Preparação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8SieorfPuL-"
      },
      "source": [
        "# Eliminacao das colunas relativas aos atributos categoricos\n",
        "\n",
        "atributosCategoricos = []\n",
        "for i in range(40):                                                               # loop para preencher um vetor com os atributos categoricos\n",
        "  if i <=3:\n",
        "    atributosCategoricos.append(\"Wilderness_Area\"+str(i+1))\n",
        "  atributosCategoricos.append(\"Soil_Type\"+str(i+1))\n",
        "\n",
        "df = df.drop(columns=atributosCategoricos)                                        # delecao dos atributos categoricos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiCQz7dNS6j7"
      },
      "source": [
        "y_alvo = df[\"Cover_Type\"]                                                         # separacao do atributo alvo\n",
        "x_preditor = df.drop(columns=[\"Cover_Type\"])                                      # separacao dos atributos preditores\n",
        "\n",
        "# Particao holdout para teste e treino\n",
        "x_train, x_test, y_train, y_test = train_test_split(                              # Criacao das particoes para treino e teste com o auxilio da biblioteca sklearn\n",
        "    x_preditor, y_alvo, test_size=0.3, train_size=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWq_wmUXP0I"
      },
      "source": [
        "# Escalonamento usando o metodo da padronização\n",
        "\n",
        "X_train_std = (x_train - np.mean(x_train))/np.std(x_train)                        # Escalonamento do conjunto de treino \n",
        "X_test_std = (x_test - np.mean(x_train))/np.std(x_train)                          # escalonamento do conjunto de teste levando em consideracao o conjunto de treino"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_laeWQ7PnVSQ"
      },
      "source": [
        "#### Criação e treinamento da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpQItHMXnVlm",
        "outputId": "f4b0f1cd-2928-4833-dc5e-b4e91b33671b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# criacao e treino da rede neural multilayer perceptron\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10),activation=\"relu\", solver=\"adam\", \n",
        "                    random_state=1, max_iter=300, \n",
        "                    verbose=True).fit(X_train_std, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.92591820\n",
            "Iteration 2, loss = 0.70723923\n",
            "Iteration 3, loss = 0.68876529\n",
            "Iteration 4, loss = 0.68025876\n",
            "Iteration 5, loss = 0.67412817\n",
            "Iteration 6, loss = 0.66988273\n",
            "Iteration 7, loss = 0.66729017\n",
            "Iteration 8, loss = 0.66543756\n",
            "Iteration 9, loss = 0.66389991\n",
            "Iteration 10, loss = 0.66283764\n",
            "Iteration 11, loss = 0.66187217\n",
            "Iteration 12, loss = 0.66094189\n",
            "Iteration 13, loss = 0.66010021\n",
            "Iteration 14, loss = 0.65948238\n",
            "Iteration 15, loss = 0.65880299\n",
            "Iteration 16, loss = 0.65824638\n",
            "Iteration 17, loss = 0.65783200\n",
            "Iteration 18, loss = 0.65745867\n",
            "Iteration 19, loss = 0.65706568\n",
            "Iteration 20, loss = 0.65674884\n",
            "Iteration 21, loss = 0.65654777\n",
            "Iteration 22, loss = 0.65634320\n",
            "Iteration 23, loss = 0.65606280\n",
            "Iteration 24, loss = 0.65580755\n",
            "Iteration 25, loss = 0.65566029\n",
            "Iteration 26, loss = 0.65553128\n",
            "Iteration 27, loss = 0.65535162\n",
            "Iteration 28, loss = 0.65533766\n",
            "Iteration 29, loss = 0.65520549\n",
            "Iteration 30, loss = 0.65506871\n",
            "Iteration 31, loss = 0.65494528\n",
            "Iteration 32, loss = 0.65480403\n",
            "Iteration 33, loss = 0.65480128\n",
            "Iteration 34, loss = 0.65467683\n",
            "Iteration 35, loss = 0.65466316\n",
            "Iteration 36, loss = 0.65457588\n",
            "Iteration 37, loss = 0.65451867\n",
            "Iteration 38, loss = 0.65446719\n",
            "Iteration 39, loss = 0.65436617\n",
            "Iteration 40, loss = 0.65435116\n",
            "Iteration 41, loss = 0.65418188\n",
            "Iteration 42, loss = 0.65423767\n",
            "Iteration 43, loss = 0.65408752\n",
            "Iteration 44, loss = 0.65414321\n",
            "Iteration 45, loss = 0.65403263\n",
            "Iteration 46, loss = 0.65402633\n",
            "Iteration 47, loss = 0.65397122\n",
            "Iteration 48, loss = 0.65396586\n",
            "Iteration 49, loss = 0.65397393\n",
            "Iteration 50, loss = 0.65380552\n",
            "Iteration 51, loss = 0.65376219\n",
            "Iteration 52, loss = 0.65376900\n",
            "Iteration 53, loss = 0.65372769\n",
            "Iteration 54, loss = 0.65359641\n",
            "Iteration 55, loss = 0.65354191\n",
            "Iteration 56, loss = 0.65350415\n",
            "Iteration 57, loss = 0.65346324\n",
            "Iteration 58, loss = 0.65336840\n",
            "Iteration 59, loss = 0.65333349\n",
            "Iteration 60, loss = 0.65320343\n",
            "Iteration 61, loss = 0.65325899\n",
            "Iteration 62, loss = 0.65316957\n",
            "Iteration 63, loss = 0.65324429\n",
            "Iteration 64, loss = 0.65305313\n",
            "Iteration 65, loss = 0.65300422\n",
            "Iteration 66, loss = 0.65305227\n",
            "Iteration 67, loss = 0.65295476\n",
            "Iteration 68, loss = 0.65295369\n",
            "Iteration 69, loss = 0.65291362\n",
            "Iteration 70, loss = 0.65283776\n",
            "Iteration 71, loss = 0.65282394\n",
            "Iteration 72, loss = 0.65277810\n",
            "Iteration 73, loss = 0.65271065\n",
            "Iteration 74, loss = 0.65278881\n",
            "Iteration 75, loss = 0.65275695\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5N-0MrNoBE9",
        "outputId": "971efc64-809a-4afc-f666-8f5033cb1d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# obtencao das respostas para o conjunto de teste\n",
        "y_pred = clf.predict(X_test_std)\n",
        "\n",
        "# print da matriz de confusao\n",
        "matrizConfusao = confusion_matrix(y_test, y_pred)                                 # calculo da matriz de confusao\n",
        "\n",
        "table = PrettyTable([\"\",\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"])                       # Cria a tabela com as colunas de 1 a 7\n",
        "table.padding_width = 1\n",
        "\n",
        "for i in range(len(matrizConfusao)):                                              # loop para preencher a tabela com os dados\n",
        "  table.add_row(np.concatenate([[str(i+1)], matrizConfusao[i]]))\n",
        "\n",
        "print(\"----------------- MATRIZ DE CONFUSAO -----------------\")                   # print da matriz de confusao\n",
        "print(table)\n",
        "\n",
        "print(\"F1-SCORE:  {}\".format(round(f1_score(y_test, y_pred,                       # calculo do f-score\n",
        "                                           average='macro'), 4))) \n",
        "print(\"ACURACIA:  {}\".format(round(accuracy_score(y_test, y_pred), 4)))           # calculo da acuracia\n",
        "print(\"PRECISION: {}\".format(round(precision_score(y_test, y_pred,                # calculo da precisao\n",
        "                                           average='macro'), 4)))\n",
        "print(\"RECALL:    {}\".format(round(recall_score(y_test, y_pred,                   # calculo da revocacao\n",
        "                                           average='macro'), 4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- MATRIZ DE CONFUSAO -----------------\n",
            "+---+-------+-------+------+-----+-----+------+------+\n",
            "|   |   1   |   2   |  3   |  4  |  5  |  6   |  7   |\n",
            "+---+-------+-------+------+-----+-----+------+------+\n",
            "| 1 | 43913 | 18200 |  8   |  0  |  8  |  9   | 1418 |\n",
            "| 2 | 15281 | 67963 | 1156 |  0  | 100 | 475  | 103  |\n",
            "| 3 |   0   |  1858 | 7512 | 131 |  0  | 1137 |  0   |\n",
            "| 4 |   0   |   4   | 375  | 271 |  0  | 145  |  0   |\n",
            "| 5 |   15  |  2547 |  46  |  0  | 323 |  10  |  0   |\n",
            "| 6 |   0   |  1463 | 2299 |  54 |  0  | 1411 |  0   |\n",
            "| 7 |  2843 |   28  |  0   |  0  |  0  |  0   | 3198 |\n",
            "+---+-------+-------+------+-----+-----+------+------+\n",
            "F1-SCORE:  0.5288\n",
            "ACURACIA:  0.7148\n",
            "PRECISION: 0.6527\n",
            "RECALL:    0.4919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aLK7ye3270j",
        "outputId": "2f221789-6a94-415e-eb99-b3603c8aa610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# treinamento usando uma aboardagem de 100 repeticoes\n",
        "\n",
        "f1scores = np.zeros(100)\n",
        "acuracias = np.zeros(100)\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10),activation=\"relu\", solver=\"adam\",       # criacao da rede neural multilayer perceptron\n",
        "                                                max_iter=300, verbose=False)\n",
        "\n",
        "for i in range (100):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(                              # Criacao das particoes para treino e teste com o auxilio da biblioteca sklearn\n",
        "    x_preditor, y_alvo, test_size=0.3, train_size=0.7)\n",
        "  \n",
        "  X_train_std = (x_train - np.mean(x_train))/np.std(x_train)                        # Escalonamento do conjunto de treino \n",
        "  X_test_std = (x_test - np.mean(x_train))/np.std(x_train)  \n",
        "\n",
        "  clf.fit(X_train_std, y_train)                                                     # treino da rede neural \n",
        "\n",
        "  y_pred = clf.predict(X_test_std)                                                  # predicao para o conjuto de teste escalonado\n",
        "\n",
        "  f1scores[i] = f1_score(y_test, y_pred, average='macro')                           # armazenamento do valor de f-score\n",
        "  acuracias[i] = accuracy_score(y_test, y_pred)                                     # armazenamento do valor de acuracia\n",
        "\n",
        "# calculo das medias e desvios padrao dos dados de acuracia e f-score\n",
        "print(\"Média de acurácia:      {}\".format(round(acuracias.mean(), 5)))              # print da media de acuracia\n",
        "print(\"Desvio Padrão acurácia: {}\".format(round(acuracias.std(), 5)))               # print do desvio padrao de acuracia\n",
        "print(\"Média de F-Score:       {}\".format(round(f1scores.mean(), 5)))               # print da media de F-Score\n",
        "print(\"Desvio Padrão F-Score:  {}\".format(round(f1scores.std(), 5)))                # print do desvio padrao de F-Score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média de acurácia:      0.71554\n",
            "Desvio Padrão acurácia: 0.0021\n",
            "Média de F-Score:       0.51661\n",
            "Desvio Padrão F-Score:  0.01065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKPt8TtY5wc6"
      },
      "source": [
        "#### Treinamento da rede neural anterior levando em consideracao o **SOLVER** sendo ***SGD***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Y3YAel6syn",
        "outputId": "f3b830fc-b7af-4996-b4db-beb069eec364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# treinamento da rede anterior usando o solver sendo sgd\n",
        "\n",
        "f1scores = np.zeros(100)\n",
        "acuracias = np.zeros(100)\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10),activation=\"relu\", solver=\"sgd\",        # criacao da rede neural com o solver sendo sgd\n",
        "                                                max_iter=300, verbose=False)\n",
        "\n",
        "for i in range (100):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(                              # Criacao das particoes para treino e teste com o auxilio da biblioteca sklearn\n",
        "    x_preditor, y_alvo, test_size=0.3, train_size=0.7)\n",
        "  \n",
        "  X_train_std = (x_train - np.mean(x_train))/np.std(x_train)                        # Escalonamento do conjunto de treino \n",
        "  X_test_std = (x_test - np.mean(x_train))/np.std(x_train)  \n",
        "\n",
        "  clf.fit(X_train_std, y_train)                                                     # treino da rede neural \n",
        "\n",
        "  y_pred = clf.predict(X_test_std)                                                  # predicao para o conjuto de teste escalonado\n",
        "\n",
        "  f1scores[i] = f1_score(y_test, y_pred, average='macro')                           # armazenamento do valor de f-score\n",
        "  acuracias[i] = accuracy_score(y_test, y_pred)                                     # armazenamento do valor de acuracia\n",
        "\n",
        "print(\"media acuracia:          {}\".format(round(acuracias.mean(), 5)))             # print da media de acuracia\n",
        "print(\"desvio padrao acuracia:  {}\".format(round(acuracias.std(), 5)))              # print do desvio padrao de acuracia\n",
        "print(\"media f-score:           {}\".format(round(f1scores.mean(), 5)))              # print da media de F-Score\n",
        "print(\"desvio padrao f-score:   {}\".format(round(f1scores.std(), 5)))               # print do desvio padrao de F-Score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "media acuracia:          0.7147\n",
            "desvio padrao acuracia:  0.00301\n",
            "media f-score:           0.48194\n",
            "desvio padrao f-score:   0.01792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EspDY_sJRlCP"
      },
      "source": [
        "### Houve influência da escolha do otimizador no desempenho da rede?\n",
        "\n",
        "***Sim***, como foi visto a partir dos dados de média e desvio padrão sobre a acurácia e o F-Score com os hiperparâmetros *solver* `adam` e `sgd`.  \n",
        "O modelo que teve o *solver* sendo adam se saiu levemente melhor, obtendo uma maior pontuação para média de f-score e ligeiramente melhor para média de acurácia também."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4P1gJcaOBon"
      },
      "source": [
        "## Discussão\n",
        "\n",
        "Nos passos anteriores, você avaliou o desempenho de uma única rede neural que contém os seguintes parâmetros: uma única camada oculta com 10 neurônios e função de ativação ReLU. O otimizador utilizado, quer seja SGD ou ADAM, trata-se do algoritmo para aproximar o gradiente do erro. Neste sentido, a escolha do otimizador é um hiperparâmetro, pois diz respeito a como a rede neural definida previamente atuará \"em tempo de execução\"  durante o processo de treinamento. Também são hiperparâmetros a quantidade de épocas, a taxa de aprendizado inicial, dentre outros.\n",
        "\n",
        "Cabe alientar também que você efetuou o treinamento desta rede por 100 vezes e apresentou os resultados em termos de média +- desvio padrão. Lembre-se que em uma rede neural há a inicialização aleatória de pesos e, em consequência, o desempenho delas está sujeito à uma flutuação estocástica. A execução destas múltiplas vezes faz com que eliminemos algum viés introduzido por uma boa ou má \"sorte\" na escolha de pesos no caso de uma única execução.\n",
        "\n",
        "## Propondo Novas Arquiteturas\n",
        "\n",
        "Variando  os parâmetros (uma ou duas camadas ocultas, com diferente números de neurônios em cada uma delas e a função de ativação) e o hiperparâmetros solver (Adam ou SGD) e o número de épocas (100,150 e 200), atenda ao que se pede:\n",
        "\n",
        "1. Proponha 10 arquiteturas distintas de RNAs para o problema em questão, à sua escolha\n",
        "2. Avalie cada uma das arquiteturas perante todos os hiperparâmetros apresentados por 100 vezes\n",
        "3. Como resultado da avaliação, apresente:  \n",
        "    3.1 Top-3 melhores redes no tocante à F-Score e Acurácia  \n",
        "    3.2 Repetição em que houve o melhor desempenho de cada uma dessas redes: ilustre tp, tf, fp e fn  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDMNIkVFcsCb"
      },
      "source": [
        "#### Criação das 10 configurações para as redes neurais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RN7_8M9WApz"
      },
      "source": [
        "funcaoAtivação = [\"identity\", \"logistic\", \"tanh\", \"relu\"]                         # declaracao do vetor com os tipos de funcao de ativacao\n",
        "hiperParametro = [\"adam\", \"sgd\"]                                                  # declaracao do vetor com o tipo do hiperparametro solver\n",
        "epocas = [100, 150, 200]                                                          # declaracao do vetor com a quanitdade de epocas\n",
        "camadas = [1, 2]\n",
        "configuracoes = []                                                                # declaracao do vetor que armazenara as configuracoes geradas\n",
        "\n",
        "for i in range (10):                                                              # loop para gerar aleatoriamente as configuracoes (dentro do especificado)\n",
        "  tipoEpoca = random.randrange(1, 1000000, 1)%3\n",
        "  tipoHiperParametro = random.randrange(1, 1000000, 1)%2\n",
        "  tipoFuncaoAtivacao = random.randrange(1, 1000000, 1)%4\n",
        "  xqtdCamadas = random.randrange(1, 1000000, 1)%2\n",
        "  qtdNeuronios = random.randrange(1, 20, 1)\n",
        "  \n",
        "  aux = random.randrange(1, qtdNeuronios, 1)                                      # variavel auxiliar\n",
        "  disposicaoNeuronios = qtdNeuronios if camadas[xqtdCamadas]==1 else (aux, \n",
        "                                                        qtdNeuronios-aux)         # disposicao dos neuronios nas 2 camadas ocultas\n",
        "\n",
        "  configuracoes.append({                                                          # armazenamento das configuracoes geradas\n",
        "    \"camadasOcultas\": camadas[xqtdCamadas],\n",
        "    \"funcaoAtivacao\": funcaoAtivação[tipoFuncaoAtivacao],\n",
        "    \"hiperparametro\": hiperParametro[tipoHiperParametro],\n",
        "    \"epocas\": epocas[tipoEpoca],\n",
        "    \"neuronios\": qtdNeuronios,\n",
        "    \"disposicaoNeuronios\": disposicaoNeuronios\n",
        "  })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NtJRzhVgnH_"
      },
      "source": [
        "#### Apresentação das configurações de redes geradas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTvv7pMcgmvQ",
        "outputId": "31160e90-89d9-4aef-ffa6-b4c4186e182c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "table = PrettyTable([\"Quantidade de camadas\",\"Função de ativação\",                  # Criacao da tabela\n",
        "                      \"Hiperparametro\", \"Quantidade de épocas\", \n",
        "                      \"Quantidade de neurônios\", \"Disposição dos neurônios\"])        \n",
        "\n",
        "table.padding_width = 1\n",
        "\n",
        "for i in configuracoes:                                                           # loop para preencher a tabela com os dados\n",
        "  table.add_row([i[\"camadasOcultas\"], i[\"funcaoAtivacao\"], i[\"hiperparametro\"],\n",
        "                i[\"epocas\"], i[\"neuronios\"], i[\"disposicaoNeuronios\"]])\n",
        "\n",
        "# print da tabela com as configuracoes geradas\n",
        "print(\"----------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS -----------------------------------------------------\")\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS -----------------------------------------------------\n",
            "+-----------------------+--------------------+----------------+----------------------+-------------------------+--------------------------+\n",
            "| Quantidade de camadas | Função de ativação | Hiperparametro | Quantidade de épocas | Quantidade de neurônios | Disposição dos neurônios |\n",
            "+-----------------------+--------------------+----------------+----------------------+-------------------------+--------------------------+\n",
            "|           1           |        tanh        |      sgd       |         150          |            11           |            11            |\n",
            "|           1           |        tanh        |      adam      |         100          |            8            |            8             |\n",
            "|           1           |        tanh        |      sgd       |         150          |            13           |            13            |\n",
            "|           1           |      logistic      |      adam      |         200          |            15           |            15            |\n",
            "|           1           |      identity      |      adam      |         200          |            12           |            12            |\n",
            "|           1           |      identity      |      sgd       |         100          |            11           |            11            |\n",
            "|           2           |      logistic      |      sgd       |         200          |            9            |          (4, 5)          |\n",
            "|           2           |      identity      |      adam      |         200          |            2            |          (1, 1)          |\n",
            "|           2           |      logistic      |      sgd       |         150          |            12           |          (6, 6)          |\n",
            "|           1           |      logistic      |      sgd       |         150          |            11           |            11            |\n",
            "+-----------------------+--------------------+----------------+----------------------+-------------------------+--------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB8xFSedmtjt"
      },
      "source": [
        "#### Treinamento das redes com os parâmetros listados acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlfNJpTNmsh9"
      },
      "source": [
        "# treinamento das 10 configuracoes geradas anteriormente\n",
        "\n",
        "melhoresMatrizes = []                                                             # vetor para armazenas as matrizes de confusao de acordo com o melhor desempenho\n",
        "desempenhoGeral = []                                                              # vetor para armazenar o desempenho de cada rede em termos de media de f-score e acuracia\n",
        "melhorDesempenhoIndividual = []                                                   # vetor para armazenar o melhor resultado de cada rede\n",
        "cont=0                                                                            # contador para marcar a posicao de cada rede na lista\n",
        "\n",
        "for i in configuracoes:                                                           # loop para o treinamento de cada configuracao de rede\n",
        "    cont+=1\n",
        "    f1scores = np.zeros(10)                                                       # incializacao do vetor de f-score com 0\n",
        "    acuracias = np.zeros(10)                                                      # inicializacao do vetor de acuracia com 0\n",
        "\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(i[\"disposicaoNeuronios\"]),            # criacao da rede neural de acordo com a configuracao em questao\n",
        "                            activation=i[\"funcaoAtivacao\"], \n",
        "                            solver=i[\"hiperparametro\"], \n",
        "                            max_iter=i[\"epocas\"], \n",
        "                            verbose=False)\n",
        "\n",
        "    for j in range(100):                                                          # loop para repetir o treinamento mais de 1 vez\n",
        "        x_train, x_test, y_train, y_test = train_test_split(\n",
        "            x_preditor, y_alvo, test_size=0.3, train_size=0.7)                    # criacao da particao holdout 70%(treino) - 30%(teste)\n",
        "        \n",
        "        X_train_std = (x_train - np.mean(x_train))/np.std(x_train)                # Escalonamento da particao de treino \n",
        "        X_test_std = (x_test - np.mean(x_train))/np.std(x_train)                  # escalonamento da particao de teste levando em consideracao a particao de treino\n",
        "\n",
        "        clf.fit(X_train_std, y_train)                                             # treino da rede\n",
        "\n",
        "        y_pred = clf.predict(X_test_std)                                          # predicao para a particao de teste\n",
        "\n",
        "        f1scores[j] = f1_score(y_test, y_pred, average='macro')                   # calculo e armazenamento do f-score\n",
        "        acuracias[j] = accuracy_score(y_test, y_pred)                             # calculo e armazenamento da acuracia\n",
        "\n",
        "        if j == 0:                                                                # logica para armazenar os melhores valores para matriz de confusao, acuracia e f-score\n",
        "          melhorDesempenhoIndividual.append({\n",
        "              \"acuracia\": acuracias[j],\n",
        "              \"fscore\": f1scores[j]\n",
        "          })\n",
        "          melhoresMatrizes.append(confusion_matrix(y_test, y_pred))\n",
        "        else:\n",
        "          if acuracias[j] >= melhorDesempenhoIndividual[cont-1][\"acuracia\"]:\n",
        "            if  acuracias[j] == melhorDesempenhoIndividual[cont-1][\"acuracia\"]:\n",
        "              if f1scores[j] > melhorDesempenhoIndividual[cont-1][\"fscore\"]:\n",
        "                melhorDesempenhoIndividual[cont-1][\"fscore\"] = f1scores[j]\n",
        "                melhorDesempenhoIndividual[cont-1][\"acuracia\"] = acuracias[j]\n",
        "                melhoresMatrizes[cont-1] = confusion_matrix(y_test, y_pred)\n",
        "            else:\n",
        "              melhorDesempenhoIndividual[cont-1][\"fscore\"] = f1scores[j]\n",
        "              melhorDesempenhoIndividual[cont-1][\"acuracia\"] = acuracias[j]\n",
        "              melhoresMatrizes[cont-1] = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    desempenhoGeral.append({                                                      # armazenamento da media para o valor de acuracia e f-score para as repeticoes\n",
        "        \"configuracao\": cont,\n",
        "        \"media\": round(acuracias.mean(), 5),\n",
        "        \"fscore\": round(f1scores.mean(), 5)\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On4g--vkjCKW",
        "outputId": "66975c93-ec6f-41a5-f44e-7387db18fd05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# print das top3 melhores redes com relacao a f-score e acuracia\n",
        "\n",
        "sorted_list = sorted(desempenhoGeral, key=lambda k: k['media'])                   # ordenacao do vetor em ordem crescente de media para acuracia\n",
        "primeiro = sorted_list[9]                                                         # extracao da melhor rede\n",
        "segundo = sorted_list[8]                                                          # extracao da segunda melhor rede\n",
        "terceiro = sorted_list[7]                                                         # extracao da terceira melhor rede\n",
        "\n",
        "table = PrettyTable([\"\", \"Camadas\",\"Função de ativação\",                          # Criacao da tabela\n",
        "                      \"Hiperparametro\", \"Épocas\", \n",
        "                      \"Quantidade de neurônios\", \"Disposição dos neurônios\", \n",
        "                     \"Média acuracia\", \"Média F-Score\"])        \n",
        "\n",
        "table.padding_width = 1\n",
        "\n",
        "# preenchimento dos dados da table (3 melhores desempenhos)\n",
        "table.add_row([\"1°\", configuracoes[primeiro[\"configuracao\"]-1][\"camadasOcultas\"], # preenchimento da posicao numero 1\n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               primeiro[\"media\"], primeiro[\"fscore\"]])\n",
        "table.add_row([\"2°\", configuracoes[segundo[\"configuracao\"]-1][\"camadasOcultas\"], # preenchimento da posicao numero 2\n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               segundo[\"media\"], segundo[\"fscore\"]])\n",
        "table.add_row([\"3°\", configuracoes[terceiro[\"configuracao\"]-1][\"camadasOcultas\"], # preenchimento da posicao numero 3\n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               terceiro[\"media\"], terceiro[\"fscore\"]])\n",
        "\n",
        "print(\"---------------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ----------------------------------------------------------\")\n",
        "print(table)\n",
        "\n",
        "# Print das matrizes de confusao das melhores configuracões\n",
        "print(\"------------- Primeiro Colocado ------------\")\n",
        "print(melhoresMatrizes[primeiro[\"configuracao\"]-1])\n",
        "\n",
        "print(\"\\n------------- Segundo Colocado -------------\")\n",
        "print(melhoresMatrizes[segundo[\"configuracao\"]-1])\n",
        "\n",
        "print(\"\\n------------- Terceiro Colocado ------------\")\n",
        "print(melhoresMatrizes[terceiro[\"configuracao\"]-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ----------------------------------------------------------\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "|    | Camadas | Função de ativação | Hiperparametro | Épocas | Quantidade de neurônios | Disposição dos neurônios | Média acuracia | Média F-Score |\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "| 1° |    1    |      logistic      |      adam      |  200   |            15           |            15            |    0.73191     |    0.54205    |\n",
            "| 2° |    1    |        tanh        |      sgd       |  150   |            13           |            13            |    0.72023     |    0.47931    |\n",
            "| 3° |    1    |        tanh        |      sgd       |  150   |            11           |            11            |    0.71824     |    0.47116    |\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "------------- Primeiro Colocado ------------\n",
            "[[46269 16352     4     0    45    35   994]\n",
            " [14522 68695  1026     0   120   460   122]\n",
            " [    0  1889  7998    33     0   690     0]\n",
            " [    0     5   499   288     0    47     0]\n",
            " [   31  2405    49     0   309    24     0]\n",
            " [    6  1425  2648    28     0  1098     0]\n",
            " [ 2505    43     0     0     0     0  3640]]\n",
            "\n",
            "------------- Segundo Colocado -------------\n",
            "[[45138 16941     7     1    14    24  1225]\n",
            " [14813 68810   902     6    76   454    41]\n",
            " [    0  1889  7956    68     0   817     0]\n",
            " [    0    10   527   186     0   137     0]\n",
            " [   30  2428    26     0   314    50     0]\n",
            " [    1  1596  2691    17     0   994     0]\n",
            " [ 3155    28     0     0     0     0  2932]]\n",
            "\n",
            "------------- Terceiro Colocado ------------\n",
            "[[44051 18009     1     0     0    23  1103]\n",
            " [13904 70014  1003     0     3   323    29]\n",
            " [    0  2151  8164   106     0   389     0]\n",
            " [    0    10   544   263     0    41     0]\n",
            " [   52  2810    16     0     8     0     0]\n",
            " [    0  1618  2919    28     0   650     0]\n",
            " [ 3340    28     0     0     0     0  2704]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olxa7kX2OBoq"
      },
      "source": [
        "## Estimando o número de neurônios\n",
        "\n",
        "Um dos problemas de pesquisa com redes neurais artificiais consiste na determinação do número de neurônios em sua arquitetura. Embora não seja possível definir a priori qual rede neural é adequada para um problema, pois isto só é possível mediante uma busca exaustiva, há regras na literatura que sugerem o número de neurônios escondidos, tal como a regra da Pirâmide Geométrica, dada a seguir:\n",
        "\n",
        "$$N_h = \\alpha \\cdot \\sqrt{N_i \\cdot N_o},$$\n",
        "\n",
        "em que $N_h$ é o número de neurônios ocultos (a serem distribuídos em uma ou duas camadas ocultas), $N_i$ é o número de neurônios na camada de entrada e $N_o$ é o número de neurônios na camada de saída. \n",
        "\n",
        "1. Consulte a documentação da classe MLPClassifier (disponível em https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) e obtenha os valores de $N_i$ e $N_h$.\n",
        "2. Teste os valores de $\\alpha$ como sendo iguais a $0.5$, $2$ e $3$.\n",
        "3. Proponha pelo menos 30 redes neurais segundo a regra da pirâmide geométrica e teste-as nos mesmos termos estabelecidos anterioremente  (solver, épocas, etc.)  \n",
        "    3.1 Apresente as top-3 melhores redes no tocante à F-Score e Acurácia  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1eqx4_J_qYz"
      },
      "source": [
        "### 1. Consulte a documentação da classe MLPClassifier e obtenha os valores de  Ni e Nh  \n",
        "Como o texto acima indica e segundo a documentação da biblioteca `sklearn.neural_network.MLPClassifier` informa, os valores para **Ni**, **No** estão relacionados a quantidade de atributos preditores e quantidade de classes respectivamente. Sendo assim, ambos correspondem respectivamente a **10** e **7**.\n",
        "\n",
        "\n",
        "### 2 e 3. Criação das 30 configuracoes para as redes neurais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLdvc6AiDutC"
      },
      "source": [
        "# Atribuicao dos parametros da regra da piramide geometrica\n",
        "Ni = 10\n",
        "No = 7\n",
        "alpha = [0.5, 2, 3]\n",
        "Nh = [] \n",
        "\n",
        "for a in alpha:\n",
        "  Nh.append(int(a*math.sqrt(Ni*No))) \n",
        "\n",
        "# print(Nh)\n",
        "# proposicao das 30 redes neurais usando a regra da pirameide para a quantidade de neuronios\n",
        "funcaoAtivação = [\"identity\", \"logistic\", \"tanh\", \"relu\"]                         # declaracao do vetor com os tipos de funcao de ativacao\n",
        "hiperParametro = [\"adam\", \"sgd\"]                                                  # declaracao do vetor com o tipo do hiperparametro solver\n",
        "epocas = [100, 150, 200]                                                          # declaracao do vetor com a quanitdade de epocas\n",
        "camadas = [1, 2]\n",
        "configuracoes = []                                                                # declaracao do vetor que armazenara as configuracoes geradas\n",
        "\n",
        "for i in range (30):                                                              # loop para gerar aleatoriamente as configuracoes (dentro do especificado)\n",
        "  tipoEpoca = random.randrange(1, 1000000, 1)%3\n",
        "  tipoHiperParametro = random.randrange(1, 1000000, 1)%2\n",
        "  tipoFuncaoAtivacao = random.randrange(1, 1000000, 1)%4\n",
        "  xqtdCamadas = random.randrange(1, 1000000, 1)%2\n",
        "  qtdNeuronios = random.randrange(1, 1000000, 1)%3\n",
        "  \n",
        "  aux = random.randrange(1, Nh[qtdNeuronios], 1)                                  # variavel auxiliar\n",
        "  disposicaoNeuronios = Nh[qtdNeuronios] if camadas[xqtdCamadas]==1 else (aux, \n",
        "                                                        Nh[qtdNeuronios]-aux)     # disposicao dos neuronios nas 2 camadas ocultas\n",
        "\n",
        "  configuracoes.append({                                                          # armazenamento das configuracoes geradas\n",
        "    \"camadasOcultas\": camadas[xqtdCamadas],\n",
        "    \"funcaoAtivacao\": funcaoAtivação[tipoFuncaoAtivacao],\n",
        "    \"hiperparametro\": hiperParametro[tipoHiperParametro],\n",
        "    \"epocas\": epocas[tipoEpoca],\n",
        "    \"neuronios\": Nh[qtdNeuronios],\n",
        "    \"disposicaoNeuronios\": disposicaoNeuronios\n",
        "  })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhDKUkj3H6EV"
      },
      "source": [
        "#### Exibição das configuracões das 30 redes propostas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnq8PjHrH5ru",
        "outputId": "3c9c6561-cdb4-4edc-b8d5-779e034e3971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "table = PrettyTable([\"Camadas\",\"Função de ativação\",                              # Criacao da tabela\n",
        "                      \"Hiperparametro\", \"Épocas\", \n",
        "                      \"Quantidade de neurônios\", \"Disposição dos neurônios\"])        \n",
        "\n",
        "table.padding_width = 1\n",
        "\n",
        "for i in configuracoes:                                                           # loop para preencher a tabela com os dados\n",
        "  table.add_row([i[\"camadasOcultas\"], i[\"funcaoAtivacao\"], i[\"hiperparametro\"],\n",
        "                i[\"epocas\"], i[\"neuronios\"], i[\"disposicaoNeuronios\"]])\n",
        "\n",
        "print(\"--------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ---------------------------------------\")\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ---------------------------------------\n",
            "+---------+--------------------+----------------+--------+-------------------------+--------------------------+\n",
            "| Camadas | Função de ativação | Hiperparametro | Épocas | Quantidade de neurônios | Disposição dos neurônios |\n",
            "+---------+--------------------+----------------+--------+-------------------------+--------------------------+\n",
            "|    1    |      logistic      |      adam      |  200   |            4            |            4             |\n",
            "|    2    |        relu        |      adam      |  150   |            25           |         (4, 21)          |\n",
            "|    2    |      identity      |      sgd       |  200   |            25           |         (20, 5)          |\n",
            "|    1    |        tanh        |      adam      |  150   |            16           |            16            |\n",
            "|    1    |        tanh        |      sgd       |  150   |            4            |            4             |\n",
            "|    2    |        relu        |      adam      |  200   |            4            |          (2, 2)          |\n",
            "|    2    |        tanh        |      adam      |  200   |            16           |         (1, 15)          |\n",
            "|    2    |      logistic      |      sgd       |  200   |            16           |         (2, 14)          |\n",
            "|    2    |        tanh        |      adam      |  200   |            4            |          (1, 3)          |\n",
            "|    2    |      logistic      |      sgd       |  200   |            4            |          (2, 2)          |\n",
            "|    2    |      logistic      |      adam      |  150   |            4            |          (2, 2)          |\n",
            "|    1    |        relu        |      sgd       |  100   |            4            |            4             |\n",
            "|    1    |      identity      |      sgd       |  100   |            4            |            4             |\n",
            "|    2    |        tanh        |      sgd       |  200   |            4            |          (1, 3)          |\n",
            "|    1    |        relu        |      sgd       |  100   |            4            |            4             |\n",
            "|    1    |        relu        |      adam      |  200   |            4            |            4             |\n",
            "|    1    |      logistic      |      sgd       |  200   |            16           |            16            |\n",
            "|    1    |        tanh        |      adam      |  100   |            4            |            4             |\n",
            "|    1    |      identity      |      sgd       |  200   |            25           |            25            |\n",
            "|    2    |      logistic      |      sgd       |  150   |            25           |         (7, 18)          |\n",
            "|    1    |      logistic      |      adam      |  100   |            25           |            25            |\n",
            "|    1    |      logistic      |      adam      |  100   |            16           |            16            |\n",
            "|    1    |        tanh        |      adam      |  150   |            25           |            25            |\n",
            "|    1    |        relu        |      adam      |  100   |            4            |            4             |\n",
            "|    1    |      identity      |      sgd       |  200   |            4            |            4             |\n",
            "|    1    |        relu        |      sgd       |  200   |            25           |            25            |\n",
            "|    1    |      identity      |      adam      |  200   |            4            |            4             |\n",
            "|    2    |      logistic      |      adam      |  200   |            25           |         (22, 3)          |\n",
            "|    1    |        relu        |      adam      |  100   |            25           |            25            |\n",
            "|    1    |        tanh        |      sgd       |  100   |            25           |            25            |\n",
            "+---------+--------------------+----------------+--------+-------------------------+--------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPNgjIQtIYAx"
      },
      "source": [
        "#### Criação e treinamento das redes neurais propostas acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbpG5lbFIXWy"
      },
      "source": [
        "# treinamento das 10 configuracoes geradas anteriormente\n",
        "\n",
        "melhoresMatrizes = []                                                             # vetor para armazenas as matrizes de confusao de acordo com o melhor desempenho\n",
        "desempenhoGeral = []                                                              # vetor para armazenar o desempenho de cada rede em termos de media de f-score e acuracia\n",
        "melhorDesempenhoIndividual = []                                                   # vetor para armazenar o melhor resultado de cada rede\n",
        "cont=0                                                                            # contador para marcar a posicao de cada rede na lista\n",
        "\n",
        "for i in configuracoes:                                                           # loop para o treinamento de cada configuracao de rede\n",
        "    cont+=1\n",
        "    f1scores = np.zeros(10)                                                       # incializacao do vetor de f-score com 0\n",
        "    acuracias = np.zeros(10)                                                      # inicializacao do vetor de acuracia com 0\n",
        "\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(i[\"disposicaoNeuronios\"]),            # criacao da rede neural de acordo com a configuracao em questao\n",
        "                            activation=i[\"funcaoAtivacao\"], \n",
        "                            solver=i[\"hiperparametro\"], \n",
        "                            max_iter=i[\"epocas\"], \n",
        "                            verbose=False)\n",
        "\n",
        "    for j in range(10):                                                          # loop para repetir o treinamento mais de 1 vez\n",
        "        x_train, x_test, y_train, y_test = train_test_split(\n",
        "            x_preditor, y_alvo, test_size=0.3, train_size=0.7)                    # criacao da particao holdout 70%(treino) - 30%(teste)\n",
        "        \n",
        "        X_train_std = (x_train - np.mean(x_train))/np.std(x_train)                # Escalonamento da particao de treino \n",
        "        X_test_std = (x_test - np.mean(x_train))/np.std(x_train)                  # escalonamento da particao de teste levando em consideracao a particao de treino\n",
        "\n",
        "        clf.fit(X_train_std, y_train)                                             # treino da rede\n",
        "\n",
        "        y_pred = clf.predict(X_test_std)                                          # predicao para a particao de teste\n",
        "\n",
        "        f1scores[j] = f1_score(y_test, y_pred, average='macro')                   # calculo e armazenamento do f-score\n",
        "        acuracias[j] = accuracy_score(y_test, y_pred)                             # calculo e armazenamento da acuracia\n",
        "\n",
        "        if j == 0:                                                                # logica para armazenar os melhores valores para matriz de confusao, acuracia e f-score\n",
        "          melhorDesempenhoIndividual.append({\n",
        "              \"acuracia\": acuracias[j],\n",
        "              \"fscore\": f1scores[j]\n",
        "          })\n",
        "          melhoresMatrizes.append(confusion_matrix(y_test, y_pred))\n",
        "        else:\n",
        "          if acuracias[j] >= melhorDesempenhoIndividual[cont-1][\"acuracia\"]:\n",
        "            if  acuracias[j] == melhorDesempenhoIndividual[cont-1][\"acuracia\"]:\n",
        "              if f1scores[j] > melhorDesempenhoIndividual[cont-1][\"fscore\"]:\n",
        "                melhorDesempenhoIndividual[cont-1][\"fscore\"] = f1scores[j]\n",
        "                melhorDesempenhoIndividual[cont-1][\"acuracia\"] = acuracias[j]\n",
        "                melhoresMatrizes[cont-1] = confusion_matrix(y_test, y_pred)\n",
        "            else:\n",
        "              melhorDesempenhoIndividual[cont-1][\"fscore\"] = f1scores[j]\n",
        "              melhorDesempenhoIndividual[cont-1][\"acuracia\"] = acuracias[j]\n",
        "              melhoresMatrizes[cont-1] = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    desempenhoGeral.append({                                                      # armazenamento da media para o valor de acuracia e f-score para as repeticoes\n",
        "        \"configuracao\": cont,\n",
        "        \"media\": round(acuracias.mean(), 5),\n",
        "        \"fscore\": round(f1scores.mean(), 5)\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_z4Y4VmNt9Z",
        "outputId": "f7f247ae-0534-449a-a0fe-4c3cd7bf3eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# print das top3 melhores redes com relacao a f-score e acuracia\n",
        "\n",
        "sorted_list = sorted(desempenhoGeral, key=lambda k: k['media'])                   # ordenacao do vetor em ordem crescente de media para acuracia\n",
        "primeiro = sorted_list[29]                                                        # extracao da melhor rede\n",
        "segundo = sorted_list[28]                                                         # extracao da segunda melhor rede\n",
        "terceiro = sorted_list[27]                                                        # extracao da terceira melhor rede\n",
        "\n",
        "table = PrettyTable([\"\", \"Camadas\",\"Função de ativação\",                          # Criacao da tabela\n",
        "                      \"Hiperparametro\", \"Épocas\", \n",
        "                      \"Quantidade de neurônios\", \"Disposição dos neurônios\", \n",
        "                     \"Média acuracia\", \"Média F-Score\"])        \n",
        "\n",
        "table.padding_width = 1\n",
        "\n",
        "# preenchimento dos dados da table (3 melhores desempenhos)\n",
        "table.add_row([\"1°\", configuracoes[primeiro[\"configuracao\"]-1][\"camadasOcultas\"], # preenchimento da posicao numero 1\n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[primeiro[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               primeiro[\"media\"], primeiro[\"fscore\"]])\n",
        "table.add_row([\"2°\", configuracoes[segundo[\"configuracao\"]-1][\"camadasOcultas\"],  # preenchimento da posicao numero 2\n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[segundo[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               segundo[\"media\"], segundo[\"fscore\"]])\n",
        "table.add_row([\"3°\", configuracoes[terceiro[\"configuracao\"]-1][\"camadasOcultas\"], # preenchimento da posicao numero 3\n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"funcaoAtivacao\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"hiperparametro\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"epocas\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"neuronios\"], \n",
        "               configuracoes[terceiro[\"configuracao\"]-1][\"disposicaoNeuronios\"],\n",
        "               terceiro[\"media\"], terceiro[\"fscore\"]])\n",
        "\n",
        "print(\"---------------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ----------------------------------------------------------\")\n",
        "print(table)\n",
        "\n",
        "# Print das matrizes de confusao das melhores configuracões\n",
        "print(\"------------- Primeiro Colocado ------------\")\n",
        "print(melhoresMatrizes[primeiro[\"configuracao\"]-1])\n",
        "\n",
        "print(\"\\n------------- Segundo Colocado -------------\")\n",
        "print(melhoresMatrizes[segundo[\"configuracao\"]-1])\n",
        "\n",
        "print(\"\\n------------- Terceiro Colocado ------------\")\n",
        "print(melhoresMatrizes[terceiro[\"configuracao\"]-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------- CONFIGURAÇÕES DAS REDES NEURAIS ----------------------------------------------------------\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "|    | Camadas | Função de ativação | Hiperparametro | Épocas | Quantidade de neurônios | Disposição dos neurônios | Média acuracia | Média F-Score |\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "| 1° |    1    |        tanh        |      adam      |  150   |            25           |            25            |    0.74959     |    0.60096    |\n",
            "| 2° |    1    |      logistic      |      adam      |  100   |            25           |            25            |    0.74573     |    0.58238    |\n",
            "| 3° |    2    |      logistic      |      adam      |  200   |            25           |         (22, 3)          |    0.74294     |    0.53948    |\n",
            "+----+---------+--------------------+----------------+--------+-------------------------+--------------------------+----------------+---------------+\n",
            "------------- Primeiro Colocado ------------\n",
            "[[47443 15300    13     0    22    11   847]\n",
            " [13227 70247  1033     0   188   331    62]\n",
            " [    0  1716  8368   115    10   535     0]\n",
            " [    0     5   275   490     0    38     0]\n",
            " [   20  2210    55     0   452    22     0]\n",
            " [   19  1368  2473    25     0  1307     0]\n",
            " [ 2480    49     0     0     0     0  3548]]\n",
            "\n",
            "------------- Segundo Colocado -------------\n",
            "[[46682 15700     3     0    16    28   956]\n",
            " [13388 70204   909     0   100   475    94]\n",
            " [    0  1636  8122   118     0   800     0]\n",
            " [    0     8   385   357     0    56     0]\n",
            " [  101  2160    56     0   457    42     0]\n",
            " [    7  1397  2496    65     0  1348     0]\n",
            " [ 2556    33     0     0     0     0  3549]]\n",
            "\n",
            "------------- Terceiro Colocado ------------\n",
            "[[46799 15899     0     0     2    26   745]\n",
            " [13407 70009  1232     0    33   446    34]\n",
            " [    0  1446  8388    72     0   781     0]\n",
            " [    0     0   413   281     0   104     0]\n",
            " [   25  2646    43     0   127    51     6]\n",
            " [    0  1168  2496    45     0  1459     0]\n",
            " [ 2431    30     0     0     0     0  3660]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UehBG1nOBos"
      },
      "source": [
        "## Testando as Redes Neurais com Atributos Categóricos\n",
        "\n",
        "1. Considere as 6 redes neurais obtidas nos dois top-3 anteriores (arquiteturas próprias e regra da pirâmide geométrica)\n",
        "2. Com todos os atributos preditores da base de dados original, incluindo os categóricos, treine e teste estas mesmas redes por 100 repetições  \n",
        "    2.1 Considere o melhor otimizador para cada uma delas  \n",
        "    2.2 Faça uso de 200 épocas para treinamento  \n",
        "    2.2 Apresente os resultados de acurácia e F-Score em termos da média +- dp para cada arquitetura\n",
        "3. Apresente o gráfico boxplot para o F-Score das 6 arquiteturas perante as 100 repetições"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVtqIl72R7aW"
      },
      "source": [
        "# criacao do vetor com as  melhores configuracoes da arquitetura propria\n",
        "top3_arquitetura = []\n",
        "top3_piramide = []\n",
        "\n",
        "# preenchimento do vetor com as 3 melhores configuracoes da arquitetura propria\n",
        "top3_arquitetura.append({                                                          \n",
        "    \"camadasOcultas\": 1,\"funcaoAtivacao\": \"logistic\", \"hiperparametro\": \"adam\",\n",
        "    \"epocas\": 200, \"neuronios\": 15, \"disposicaoNeuronios\": 15\n",
        "  })\n",
        "top3_arquitetura.append({                                                          \n",
        "    \"camadasOcultas\": 1, \"funcaoAtivacao\": \"tanh\", \"hiperparametro\": \"sgd\",\n",
        "    \"epocas\": 200, \"neuronios\": 13, \"disposicaoNeuronios\": 13\n",
        "  })\n",
        "top3_arquitetura.append({                                                          \n",
        "    \"camadasOcultas\": 1, \"funcaoAtivacao\": \"tanh\", \"hiperparametro\": \"sgd\",\n",
        "    \"epocas\": 200, \"neuronios\": 11, \"disposicaoNeuronios\": 11\n",
        "  })\n",
        "\n",
        "# preenchimento do vetor com as 3 melhores configuracoes da arquitetura priramide\n",
        "top3_piramide.append({                                                          \n",
        "    \"camadasOcultas\": 1,\"funcaoAtivacao\": \"tanh\", \"hiperparametro\": \"adam\",\n",
        "    \"epocas\": 200, \"neuronios\": 25, \"disposicaoNeuronios\": 25\n",
        "  })\n",
        "top3_piramide.append({                                                          \n",
        "    \"camadasOcultas\": 1, \"funcaoAtivacao\": \"logistic\", \"hiperparametro\": \"adam\",\n",
        "    \"epocas\": 200, \"neuronios\": 25, \"disposicaoNeuronios\": 25\n",
        "  })\n",
        "top3_piramide.append({                                                          \n",
        "    \"camadasOcultas\": 2, \"funcaoAtivacao\": \"logistic\", \"hiperparametro\": \"adam\",\n",
        "    \"epocas\": 200, \"neuronios\": 25, \"disposicaoNeuronios\": (22, 3)\n",
        "  })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEvL8grsOBot"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/covtype.csv', sep=',')  # leitura do dataset com todos os atributos\n",
        "y_alvo = df[\"Cover_Type\"]                                                         # separacao do atributo alvo\n",
        "x_preditor = df.drop(columns=[\"Cover_Type\"])                                      # separacao dos atributos preditores\n",
        "\n",
        "top_6 = []                                                                        # Vetor dos top 6\n",
        "top_6 = top3_arquitetura + top3_piramide                                          # soma do vetor de arquitetura proprie e de piramide geometrica\n",
        "\n",
        "ranking_top6 = []                                                                 # inicializacao do vetor com o raking das configuracoes\n",
        "fscore_top6 = []                                                                  # inicializacao do vetor com o f-score para cada configuracao\n",
        "acuracia_top6 = []                                                                # inicializacao do vetor com a acuracia para cada configuracao\n",
        "cont=0\n",
        "for i in top_6:                                                                   # loop para cada configuracao\n",
        "    fscore_top6.append([])\n",
        "    acuracia_top6.append([])\n",
        "    cont+=1\n",
        "    f1scores = np.zeros(10)\n",
        "    acuracias = np.zeros(10)\n",
        "\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(i[\"disposicaoNeuronios\"]),\n",
        "                            activation=i[\"funcaoAtivacao\"], \n",
        "                            solver=i[\"hiperparametro\"], \n",
        "                            max_iter=200, #sao 200 epocas \n",
        "                            verbose=False)\n",
        "    for j in range(10):\n",
        "        x_train, x_test, y_train, y_test = train_test_split(                      # Criacao das particoes para treino e teste com o auxilio da biblioteca sklearn\n",
        "            x_preditor, y_alvo, test_size=0.3, train_size=0.7)\n",
        "        \n",
        "        clf.fit(x_train, y_train)                                                 # treino da rede\n",
        "\n",
        "        y_pred = clf.predict(x_test)                                              # predicao para a particao de teste\n",
        "\n",
        "        fscore_top6[cont - 1].append(f1_score(y_test, y_pred, average='macro'))   # Calcula o fscore e coloca no score do top6\n",
        "        acuracia_top6[cont - 1].append(accuracy_score(y_test, y_pred))            # Calcula a acuracia e coloca no score do top6\n",
        "\n",
        "    ranking_top6.append({                                                         # armazenamento do resultado para media e desvio padrao de acuracia e f-score\n",
        "        \"configuracao\": cont,\n",
        "        \"mediaAcuracia\": np.mean(acuracia_top6[cont-1]),\n",
        "        \"desvioacuracia\": np.std(acuracia_top6[cont-1]),\n",
        "        \"mediafscore\": np.mean(fscore_top6[cont-1]),\n",
        "        \"desvioFscore\": np.std(fscore_top6[cont-1])\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsiv2yajXgjW",
        "outputId": "4f18b459-e526-4dad-d9a4-4387e73abec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# plot do boxplot para fs-score\n",
        "\n",
        "boxplot_top6 = pd.DataFrame(fscore_top6)                                          # pegar o fscore e botar num dataframe\n",
        "boxplot_top6 = boxplot_top6.transpose()                                           # arrumar o dataframe\n",
        " \n",
        "boxplot_top6.boxplot()                                                            # plotar em um boxplot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa4d926b550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVEFC7QqRJnN",
        "outputId": "d0e691c9-3700-4dd9-b820-ff869e034539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "table = PrettyTable([\"Indice da configuração\", \"Média acuracia\",                  # Criacao da tabela\n",
        "                     \"Desvio acuracia\", \"Média F-Score\", \"Desvio F-Score\"])        \n",
        "cont = 0\n",
        "table.padding_width = 1\n",
        "\n",
        "for i in ranking_top6:                                                            # preecnhimento dos dados na tabela\n",
        "  cont+=1\n",
        "  table.add_row([cont, round(i[\"mediaAcuracia\"],5), \n",
        "                       round(i[\"desvioacuracia\"],5),\n",
        "                       round(i[\"mediafscore\"],5), \n",
        "                       round(i[\"desvioFscore\"], 5)])\n",
        "  \n",
        "print(\"------------------------------ CONFIGURAÇÕES DAS REDES NEURAIS -------------------------------\")\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------ CONFIGURAÇÕES DAS REDES NEURAIS -------------------------------\n",
            "+------------------------+----------------+-----------------+---------------+----------------+\n",
            "| Indice da configuração | Média acuracia | Desvio acuracia | Média F-Score | Desvio F-Score |\n",
            "+------------------------+----------------+-----------------+---------------+----------------+\n",
            "|           1            |    0.69924     |     0.01157     |    0.35566    |    0.02693     |\n",
            "|           2            |    0.48741     |     0.00094     |    0.09363    |    0.00012     |\n",
            "|           3            |     0.4877     |     0.00057     |    0.09366    |     7e-05      |\n",
            "|           4            |    0.69278     |     0.01075     |    0.33883    |    0.03276     |\n",
            "|           5            |    0.70932     |     0.00783     |    0.41649    |    0.04528     |\n",
            "|           6            |    0.70581     |     0.00941     |    0.35385    |    0.04163     |\n",
            "+------------------------+----------------+-----------------+---------------+----------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B7-fC8IOBov"
      },
      "source": [
        "## Considerações Parciais\n",
        "\n",
        "1. É possível identificar uma rede com desempenho superior às demais?\n",
        "2. Qual estratégia mostrou-se mais producente para a obtenção de boas arquiteturas (Estratégia Própria ou Pirâmide Geométrica)? Por quê?\n",
        "3. Considerar os atributos categóricos trouxe melhorias? Justifique.\n",
        "4. Um número maior de épocas trouxe melhorias?\n",
        "5. Qual a maior dificuldade de resolução do problema proposto perante as RNAs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGOg6V-nbXKo"
      },
      "source": [
        "**1.**   \n",
        "\n",
        "***Sim.***  \n",
        "De acordo com as execuções das redes neurais feitas por esse projeto, existem redes que possuem melhores acurácias e melhores F-Scores do que outras, enquanto algumas redes se estagnaram, outras tiveram resultados levemente superiores, obtendo assim melhores resultados para suas médias.  \n",
        "No entanto pode-se dizer que todas as redes obtiveram um desempenho de certa forma similar, não se diferenciando em mais de 10% umas das outras.  \n",
        "\n",
        "***\n",
        "**2.**  \n",
        "\n",
        "Como é possivel ver na tabela acima, que consta as 6 melhores configurações encontradas, é possível perceber que as configurações de índice 4, 5, 6 (que foram obtidas pela regra da **pirâmide geométrica**) foram **superiores** no quesito de média de *F-Score* e *Acurácia*.  \n",
        "Sendo assim, pode-se afirmar que a regra da pirâmide geométrica é mais eficiente que uma escolha aleatória, que foi a utilizada na estratégia própria.\n",
        "\n",
        "Isso pode ser justificado pelo fato de a regra da pirâmide geometrica tentar encontrar um \"meio termo\" entre a quantidade de neurônios para uma rede ja que usar poucos neurônios nas camadas ocultas pode resultar em algo chamado *underfitting* que é quando há poucos neurônios nas camadas ocultas para detectar adequadamente os sinais em um conjunto de dados. No entanto aumentar muito a quantidade de neuronios pode resultar em algo chamado *overfitting* que é quando ocorre de a rede neural ter muita capacidade de processamento de informações que a base de dados não é capaz de suprir essas informações, sendo assim, uma escolha randomica pode cair em um desses problemas e a regra da piramide geometrica visa fazer uso de parametros da rede para gerar esse valor para quantidade de neurônios podendo esse ser o fator para sua leve superioridade sobre o outro método.\n",
        "\n",
        "***\n",
        "**3.**\n",
        "\n",
        "Para os treinos executados, a utilização dos atributos categóricos **piorou** em relação a não utilização dos mesmos.  \n",
        "Isso pode ser facilmente visualizado ao se comparar os resultados obtidos nas execuções anteriores, por exemplo, a melhor configuração de rede, usando a pirâmide geométrica, teve um score de ***0.74*** para acurácia sem o uso dos atributos categóricos, enquanto o uso teve um score de ***0.70***, mostrando assim uma certa inferioridade.\n",
        "\n",
        "***\n",
        "**4.**\n",
        "\n",
        "Durante a execução dos testes, foi possível visualizar que as redes que atingiam a convergência antes de alcançarem a quantidade máxima de épocas **não sofreram grandes alterações** com o aumento das mesmas. *No entanto*, as redes que puderam tirar vantagem disso obtiam uma pontuação levemente superior.\n",
        "\n",
        "***\n",
        "**5.**\n",
        "\n",
        "É possível citar algumas dificuldades que a equipe pode identificar durante a execução do projeto, no que diz respeito aos desafios ao se resolver um problema usando redes neurais, quais sejam:\n",
        "\n",
        "* Dificuldade na escolha dos parâmetros para as redes neurais - Foi possível constatar que uma escolha de parâmetros pode influenciar de forma direta o desempenho de uma rede neural, sendo assim, busca-se encontrar os \"melhores\" parâmetros para um determinado problema. Mas isso não é uma tarefa trivial, já que seria necessário explorar **todas** as possibilidades para se poder afirmar o resultado final. Sendo assim pode-se dizer que as redes neurais tem um empecilho que define diretamente o seu desempenho.  \n",
        "\n",
        "* Dificuldade no que diz respeito ao tempo de execução e recursos computacionais - Esse é um ponto de suma importância, já que redes neurais são capazes de resolver uma enorme gama de problemas, no entanto, há um custo para essa versatilidade, que seria os recusos computacionais para se treinar uma rede neural. O tempo de execução para o treino de redes neurais é proporcional à quantidade de neurônios utilizados (mais um fator para se escolher bem os parâmetros da rede), por essa razão, a equipe decidiu executar os treinamentos com 10 iterações.  \n",
        "Apenas exemplificando rapidamente, no começo, foi utilizado 100 iterações para o treino da rede, o treinamento de **uma** rede como um todo demorou cerca de 4 horas. Se todas as 49 redes fossem treinadas dessa maneira, as execuções não terminariam em tempo cabível.  \n",
        "Quando essas iterações foram diminuídas para 10, o treino de **uma** rede diminuiu para cerca de 20 minutos. Isso viabilizou a execução de todas as redes deste notebook."
      ]
    }
  ]
}