{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "PP3.3 - Proposição e Avaliação de RNAs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-IPPbpROBoi"
      },
      "source": [
        "## Redes Neurais Artificiais 2020.1\n",
        "\n",
        "**Disciplina**: Redes Neurais Artificiais 2020.1  \n",
        "**Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
        "**Github**: http://github.com/elloa  \n",
        "        \n",
        "\n",
        "Levando em conta a base de dados **_Forest Cover Type_**, esta terceira parte do Projeto Prático 3 diz respeito à proposição e avaliação de múltiplas redes neurais artificiais do tipo feedforward multilayer perceptron para o problema da classificação multi-classe da cobertura florestal em uma área do Roosevelt National Forest.\n",
        "\n",
        "## Testando Redes Neurais sem os Atributos Categórios\n",
        "\n",
        "1. Abra a base de dados em questão\n",
        "2. Elimine todas as colunas relativas aos atributos categóricos\n",
        "3. Armazene o atributo alvo em uma variável y e os atributos preditores em uma variável X\n",
        "4. Efetue uma partição holdout 70/30 com o sklearn, distribuindo os exemplos de maneira aleatória\n",
        "5. Efetue o escalonamento dos atributos\n",
        "\n",
        "### Escalonando os atributos\n",
        "\n",
        "O treinamento de uma rede neural artificial é mais eficiente quando os valores que lhes são fornecidos como entrada são pequenos, pois isto favorece a convergência. Isto é feito escalonando-se todos os atributos para o intervalo [0,1], mas precisa ser feito de maneira cautelosa, para que informações do conjunto de teste não sejam fornecidas no treinamento.\n",
        "\n",
        "Há duas estratégias para tal escalonamento: normalização e padronização. Ambas possuem características particulares, vantagens e limitações, como é possível ver aqui: https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
        "\n",
        "\n",
        "No nosso caso, vamos usar a padronização. Assim, com os atributos preditores do treinamento, isto é, X_train, deve-se subtrair a média e dividir pelo desvio padrão:\n",
        "\n",
        "X_train_std = (X_train - np.mean(X_train))/np.std(X_train)\n",
        "\n",
        "Em seguida, o mesmo deve ser feito com os atributos preditores do conjunto de testes, mas com padronização relativa ao conjunto de treinamento:\n",
        "\n",
        "X_test_std = (X_test - np.mean(X_train))/np.std(X_train)\n",
        "\n",
        "Se todo o conjunto X for utilizado na padronização, a rede neural receberá informações do conjunto de teste por meio da média e variância utilizada para preparar os dados de treinamento, o que não é desejável.\n",
        "\n",
        "\n",
        "### Continuando\n",
        "\n",
        "5. Treine uma rede neural multilayer perceptron para este problema com uma única camada e dez neurônios  \n",
        "    5.1 Utilize a função de ativação ReLU  \n",
        "    5.2 Utilize o solver Adam    \n",
        "    5.3 Imprima o passo a passo do treinamento    \n",
        "    5.4 Utilize o número máximo de épocas igual a 300  \n",
        "6. Com o modelo em questão, após o treinamento, apresente:  \n",
        "    6.1 Matriz de confusão para o conjunto de teste  \n",
        "    6.2 Acurácia  \n",
        "    6.3 F-Score  \n",
        "    6.4 Precisão  \n",
        "    6.5 Revocação  \n",
        "7. Repita o treinamento da mesma rede anterior sem imprimir o passo a passo (verbose False) por 100 vezes  \n",
        "    7.1 Cada uma destas repetições deve ser feita com uma nova partição Holdout  \n",
        "    7.2 Apresente a média e o desvio padrão da acurácia e do F-Score para o conjunto de treino  \n",
        "8. Repita por 100 vezes o treinamento desta mesma rede, mas utilizando o otimizador SGD  \n",
        "    8.1 Apresente a média e o desvio padrão da acurácia e do F-Score para o conjunto de treino  \n",
        "9. Houve influência da escolha do otimizador no desempenho da rede?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1laST-NOBok"
      },
      "source": [
        "## Reservado para a importação de bibliotecas\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objects as go\n",
        "import math\n",
        "from prettytable import PrettyTable  \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG8mF9yzOynH",
        "outputId": "c1fab8d8-349a-4dd4-d89b-381241900f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Montagem do drive para o carregamento da base de dados por meio do google colab\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWmV3nMGO0FG"
      },
      "source": [
        "# Leitura do dataset covtype.csv\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/covtype.csv', sep=',')  # caso use google colab\n",
        "# df = pd.read_csv('./covtype.csv')                                               # caso faça localmente pelo jupyter"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-gwBze5Pt13"
      },
      "source": [
        "#### Preparação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8SieorfPuL-"
      },
      "source": [
        "# Eliminacao das colunas relativas aos atributos categoricos\n",
        "\n",
        "atributosCategoricos = []\n",
        "for i in range(40):                                                               # loop para preencher um vetor com os atributos categoricos\n",
        "  if i <=3:\n",
        "    atributosCategoricos.append(\"Wilderness_Area\"+str(i+1))\n",
        "  atributosCategoricos.append(\"Soil_Type\"+str(i+1))\n",
        "\n",
        "df = df.drop(columns=atributosCategoricos)                                        # delecao dos atributos categoricos"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiCQz7dNS6j7"
      },
      "source": [
        "y_alvo = df[\"Cover_Type\"]                                                         # separacao do atributo alvo\n",
        "x_preditor = df.drop(columns=[\"Cover_Type\"])                                      # separacao dos atributos preditores\n",
        "\n",
        "# Particao holdout para teste e treino\n",
        "x_train, x_test, y_train, y_test = train_test_split(                              # Criacao das particoes para treino e teste com o auxilio da biblioteca sklearn\n",
        "    x_preditor, y_alvo, test_size=0.3, train_size=0.7, random_state=42)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWq_wmUXP0I",
        "outputId": "3b3aa95d-02af-44cb-89c5-d22674153ed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Escalonamento\n",
        "\n",
        "X_train_std = (x_train - np.mean(x_train))/np.std(x_train)\n",
        "X_train_std"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>110220</th>\n",
              "      <td>-1.213285</td>\n",
              "      <td>1.521970</td>\n",
              "      <td>-1.215756</td>\n",
              "      <td>-0.985653</td>\n",
              "      <td>-0.709902</td>\n",
              "      <td>-0.962484</td>\n",
              "      <td>-0.229567</td>\n",
              "      <td>0.541278</td>\n",
              "      <td>0.614032</td>\n",
              "      <td>-0.199579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363425</th>\n",
              "      <td>0.666947</td>\n",
              "      <td>-0.684312</td>\n",
              "      <td>-0.413945</td>\n",
              "      <td>-0.444373</td>\n",
              "      <td>0.182714</td>\n",
              "      <td>-0.831053</td>\n",
              "      <td>0.817019</td>\n",
              "      <td>-0.166989</td>\n",
              "      <td>-0.667745</td>\n",
              "      <td>-0.668463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111410</th>\n",
              "      <td>0.178158</td>\n",
              "      <td>1.039625</td>\n",
              "      <td>-0.280310</td>\n",
              "      <td>1.447756</td>\n",
              "      <td>-0.229263</td>\n",
              "      <td>2.016207</td>\n",
              "      <td>-0.864994</td>\n",
              "      <td>0.996592</td>\n",
              "      <td>1.346476</td>\n",
              "      <td>-0.496589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552313</th>\n",
              "      <td>-0.289224</td>\n",
              "      <td>0.512618</td>\n",
              "      <td>1.590582</td>\n",
              "      <td>-0.952706</td>\n",
              "      <td>-0.194931</td>\n",
              "      <td>0.389659</td>\n",
              "      <td>-0.939750</td>\n",
              "      <td>1.502497</td>\n",
              "      <td>1.241841</td>\n",
              "      <td>-0.500358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107881</th>\n",
              "      <td>0.745438</td>\n",
              "      <td>-1.068401</td>\n",
              "      <td>-1.082121</td>\n",
              "      <td>-0.364357</td>\n",
              "      <td>-0.349423</td>\n",
              "      <td>0.473647</td>\n",
              "      <td>0.293726</td>\n",
              "      <td>0.136554</td>\n",
              "      <td>-0.013777</td>\n",
              "      <td>1.807877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110268</th>\n",
              "      <td>0.795388</td>\n",
              "      <td>-0.764703</td>\n",
              "      <td>-0.146675</td>\n",
              "      <td>0.435797</td>\n",
              "      <td>-0.109103</td>\n",
              "      <td>0.411458</td>\n",
              "      <td>0.817019</td>\n",
              "      <td>-0.470532</td>\n",
              "      <td>-0.877015</td>\n",
              "      <td>1.774708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259178</th>\n",
              "      <td>0.759710</td>\n",
              "      <td>0.003476</td>\n",
              "      <td>1.991488</td>\n",
              "      <td>2.102000</td>\n",
              "      <td>4.199487</td>\n",
              "      <td>-0.766940</td>\n",
              "      <td>0.929153</td>\n",
              "      <td>0.237735</td>\n",
              "      <td>-1.164761</td>\n",
              "      <td>0.644713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365838</th>\n",
              "      <td>0.691921</td>\n",
              "      <td>1.173609</td>\n",
              "      <td>0.387866</td>\n",
              "      <td>0.308713</td>\n",
              "      <td>-0.091937</td>\n",
              "      <td>-0.674617</td>\n",
              "      <td>-1.537799</td>\n",
              "      <td>0.693049</td>\n",
              "      <td>1.634222</td>\n",
              "      <td>0.047678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131932</th>\n",
              "      <td>0.377955</td>\n",
              "      <td>1.718481</td>\n",
              "      <td>0.922406</td>\n",
              "      <td>-0.684419</td>\n",
              "      <td>-0.469582</td>\n",
              "      <td>1.522537</td>\n",
              "      <td>-1.313531</td>\n",
              "      <td>-1.077617</td>\n",
              "      <td>0.430921</td>\n",
              "      <td>-1.023518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121958</th>\n",
              "      <td>0.220971</td>\n",
              "      <td>-1.157725</td>\n",
              "      <td>0.254231</td>\n",
              "      <td>-0.985653</td>\n",
              "      <td>-0.675571</td>\n",
              "      <td>1.032713</td>\n",
              "      <td>-0.042676</td>\n",
              "      <td>-0.976436</td>\n",
              "      <td>-0.458475</td>\n",
              "      <td>0.387656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>406708 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Elevation    Aspect  ...  Hillshade_3pm  Horizontal_Distance_To_Fire_Points\n",
              "110220  -1.213285  1.521970  ...       0.614032                           -0.199579\n",
              "363425   0.666947 -0.684312  ...      -0.667745                           -0.668463\n",
              "111410   0.178158  1.039625  ...       1.346476                           -0.496589\n",
              "552313  -0.289224  0.512618  ...       1.241841                           -0.500358\n",
              "107881   0.745438 -1.068401  ...      -0.013777                            1.807877\n",
              "...           ...       ...  ...            ...                                 ...\n",
              "110268   0.795388 -0.764703  ...      -0.877015                            1.774708\n",
              "259178   0.759710  0.003476  ...      -1.164761                            0.644713\n",
              "365838   0.691921  1.173609  ...       1.634222                            0.047678\n",
              "131932   0.377955  1.718481  ...       0.430921                           -1.023518\n",
              "121958   0.220971 -1.157725  ...      -0.458475                            0.387656\n",
              "\n",
              "[406708 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4P1gJcaOBon"
      },
      "source": [
        "## Discussão\n",
        "\n",
        "Nos passos anteriores, você avaliou o desempenho de uma única rede neural que contém os seguintes parâmetros: uma única camada oculta com 10 neurônios e função de ativação ReLU. O otimizador utilizado, quer seja SGD ou ADAM, trata-se do algoritmo para aproximar o gradiente do erro. Neste sentido, a escolha do otimizador é um hiperparâmetro, pois diz respeito a como a rede neural definida previamente atuará \"em tempo de execução\"  durante o processo de treinamento. Também são hiperparâmetros a quantidade de épocas, a taxa de aprendizado inicial, dentre outros.\n",
        "\n",
        "Cabe alientar também que você efetuou o treinamento desta rede por 100 vezes e apresentou os resultados em termos de média +- desvio padrão. Lembre-se que em uma rede neural há a inicialização aleatória de pesos e, em consequência, o desempenho delas está sujeito à uma flutuação estocástica. A execução destas múltiplas vezes faz com que eliminemos algum viés introduzido por uma boa ou má \"sorte\" na escolha de pesos no caso de uma única execução.\n",
        "\n",
        "## Propondo Novas Arquiteturas\n",
        "\n",
        "Variando  os parâmetros (uma ou duas camadas ocultas, com diferente números de neurônios em cada uma delas e a função de ativação) e o hiperparâmetros solver (Adam ou SGD) e o número de épocas (100,150 e 200), atenda ao que se pede:\n",
        "\n",
        "1. Proponha 10 arquiteturas distintas de RNAs para o problema em questão, à sua escolha\n",
        "2. Avalie cada uma das arquiteturas perante todos os hiperparâmetros apresentados por 100 vezes\n",
        "3. Como resultado da avaliação, apresente:  \n",
        "    3.1 Top-3 melhores redes no tocante à F-Score e Acurácia  \n",
        "    3.2 Repetição em que houve o melhor desempenho de cada uma dessas redes: ilustre tp, tf, fp e fn  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoIj2ptKOBon"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olxa7kX2OBoq"
      },
      "source": [
        "## Estimando o número de neurônios\n",
        "\n",
        "Um dos problemas de pesquisa com redes neurais artificiais consiste na determinação do número de neurônios em sua arquitetura. Embora não seja possível definir a priori qual rede neural é adequada para um problema, pois isto só é possível mediante uma busca exaustiva, há regras na literatura que sugerem o número de neurônios escondidos, tal como a regra da Pirâmide Geométrica, dada a seguir:\n",
        "\n",
        "$$N_h = \\alpha \\cdot \\sqrt{N_i \\cdot N_o},$$\n",
        "\n",
        "em que $N_h$ é o número de neurônios ocultos (a serem distribuídos em uma ou duas camadas ocultas), $N_i$ é o número de neurônios na camada de entrada e $N_o$ é o número de neurônios na camada de saída. \n",
        "\n",
        "1. Consulte a documentação da classe MLPClassifier (disponível em https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) e obtenha os valores de $N_i$ e $N_h$.\n",
        "2. Teste os valores de $\\alpha$ como sendo iguais a $0.5$, $2$ e $3$.\n",
        "3. Proponha pelo menos 30 redes neurais segundo a regra da pirâmide geométrica e teste-as nos mesmos termos estabelecidos anterioremente  (solver, épocas, etc.)  \n",
        "    3.1 Apresente as top-3 melhores redes no tocante à F-Score e Acurácia  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWkbbHy2OBoq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UehBG1nOBos"
      },
      "source": [
        "## Testando as Redes Neurais com Atributos Categóricos\n",
        "\n",
        "1. Considere as 6 redes neurais obtidas nos dois top-3 anteriores (arquiteturas próprias e regra da pirâmide geométrica)\n",
        "2. Com todos os atributos preditores da base de dados original, incluindo os categóricos, treine e teste estas mesmas redes por 100 repetições  \n",
        "    2.1 Considere o melhor otimizador para cada uma delas  \n",
        "    2.2 Faça uso de 200 épocas para treinamento  \n",
        "    2.2 Apresente os resultados de acurácia e F-Score em termos da média +- dp para cada arquitetura\n",
        "3. Apresente o gráfico boxplot para o F-Score das 6 arquiteturas perante as 100 repetições"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEvL8grsOBot"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B7-fC8IOBov"
      },
      "source": [
        "## Considerações Parciais\n",
        "\n",
        "1. É possível identificar uma rede com desempenho superior às demais?\n",
        "2. Qual estratégia mostrou-se mais producente para a obtenção de boas arquiteturas (Estratégia Própria ou Pirâmide Geométrica)? Por quê?\n",
        "3. Considerar os atributos categóricos trouxe melhorias? Justifique.\n",
        "4. Um número maior de épocas trouxe melhorias?\n",
        "5. Qual a maior dificuldade de resolução do problema proposto perante as RNAs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItP1HTw8OBow"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}